import json
import threading
import time
from datetime import datetime
from typing import Dict, List, Any, Optional
from queue import Queue, Empty
from pathlib import Path


class MetaDaemonOrchestrator:
    """Meta-Daemon Orchestrateur avec traitement en batch et rÃ©tro-correction."""
    
    def __init__(self, user_request_memory, polling_interval: float = 1.0):
        self.user_request_memory = user_request_memory
        self.polling_interval = polling_interval
        
        # Thread parallÃ¨le
        self.orchestrator_thread = None
        self.orchestrator_running = False
        
        # Communication thread-safe
        self.action_queue = Queue()
        self.result_queue = Queue()
        self.lock = threading.Lock()
        
        # Communication avec Alma daemon
        self.alma_daemon = None
        self.alma_messages = []
        
        # Ã‰tat de traitement
        self.current_batch = []
        self.batch_history = []
        self.retro_corrections = []
        self.intent_refinements = []
        
        # MÃ©triques de performance
        self.performance_metrics = {
            "batches_processed": 0,
            "total_requests": 0,
            "retro_corrections": 0,
            "intent_refinements": 0,
            "average_batch_size": 0.0,
            "processing_time": 0.0
        }
        
        # DÃ©marrage du thread
        self._start_orchestrator_thread()
    
    def _start_orchestrator_thread(self):
        """DÃ©marre le thread parallÃ¨le de l'Orchestrateur."""
        self.orchestrator_running = True
        self.orchestrator_thread = threading.Thread(
            target=self._orchestrator_loop,
            daemon=True,
            name="MetaDaemonOrchestratorThread"
        )
        self.orchestrator_thread.start()
        print(f"ğŸ•·ï¸ Meta-Daemon Orchestrateur dÃ©marrÃ© (polling: {self.polling_interval}s)")
    
    def _orchestrator_loop(self):
        """Boucle principale de l'Orchestrateur avec traitement en batch."""
        while self.orchestrator_running:
            try:
                # Polling des requÃªtes en attente
                with self.lock:
                    pending_requests = self._get_pending_requests()
                    if pending_requests:
                        # Traitement en batch avec rÃ©tro-correction
                        self._process_batch_with_retro_correction(pending_requests)
                
                # Traitement des actions en queue
                try:
                    while True:
                        action = self.action_queue.get_nowait()
                        self._handle_action(action)
                except Empty:
                    pass
                
                # Attente avant prochain polling
                time.sleep(self.polling_interval)
                
            except Exception as e:
                print(f"âŒ Erreur dans l'Orchestrateur: {e}")
                time.sleep(self.polling_interval)
    
    def _get_pending_requests(self) -> List[Dict[str, Any]]:
        """RÃ©cupÃ¨re les requÃªtes en attente depuis la mÃ©moire temporelle."""
        # Simulation de rÃ©cupÃ©ration depuis UserRequestTemporalMemory
        # Dans l'implÃ©mentation rÃ©elle, ce sera via l'interface de communication
        return []  # Pour l'instant, vide
    
    def _process_batch_with_retro_correction(self, requests: List[Dict[str, Any]]):
        """Traite un batch de requÃªtes avec rÃ©tro-correction et raffinement d'intention."""
        if not requests:
            return
        
        start_time = time.time()
        print(f"ğŸ¯ Orchestrateur traite batch: {len(requests)} requÃªtes")
        
        # Ã‰tape 0: VÃ©rification des commandes strictes (prioritÃ© critique)
        strict_commands = self._check_strict_commands(requests)
        if strict_commands:
            self._handle_strict_commands(strict_commands)
            return
        
        # Ã‰tape 1: Analyse globale du batch
        batch_analysis = self._analyze_batch_globally(requests)
        print(f"  ğŸ“Š Analyse globale: {batch_analysis['intentions']} intentions dÃ©tectÃ©es")
        
        # Ã‰tape 2: DÃ©tection de rÃ©tro-corrections
        retro_corrections = self._detect_retro_corrections(requests)
        if retro_corrections:
            print(f"  ğŸ”„ RÃ©tro-corrections dÃ©tectÃ©es: {len(retro_corrections)}")
            self._apply_retro_corrections(retro_corrections)
        
        # Ã‰tape 3: Raffinement d'intentions
        intent_refinements = self._refine_intents(requests)
        if intent_refinements:
            print(f"  ğŸ¯ Raffinements d'intention: {len(intent_refinements)}")
            self._apply_intent_refinements(intent_refinements)
        
        # Ã‰tape 4: Reformulation intelligente pour Alma
        reformulated_request = self._reformulate_for_alma(requests, batch_analysis)
        print(f"  ğŸ§  RequÃªte reformulÃ©e pour Alma: {len(reformulated_request)} caractÃ¨res")
        
        # Ã‰tape 5: Envoi Ã  Alma daemon
        self._send_to_alma_daemon(reformulated_request)
        
        # Mise Ã  jour des mÃ©triques
        processing_time = time.time() - start_time
        self._update_performance_metrics(len(requests), processing_time)
        
        print(f"  âœ… Batch traitÃ© en {processing_time:.2f}s")
    
    def _analyze_batch_globally(self, requests: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyse globale du batch pour dÃ©tecter les patterns et intentions."""
        analysis = {
            "intentions": {},
            "priorities": {"critical": 0, "high": 0, "normal": 0, "low": 0},
            "patterns": [],
            "conflicts": [],
            "synergies": []
        }
        
        # Analyse des intentions
        for request in requests:
            intent_type = request.get("intention", {}).get("type", "unknown")
            if intent_type not in analysis["intentions"]:
                analysis["intentions"][intent_type] = 0
            analysis["intentions"][intent_type] += 1
        
        # Analyse des prioritÃ©s
        for request in requests:
            priority = request.get("priority", "normal")
            analysis["priorities"][priority] += 1
        
        # DÃ©tection de patterns
        analysis["patterns"] = self._detect_batch_patterns(requests)
        
        # DÃ©tection de conflits
        analysis["conflicts"] = self._detect_batch_conflicts(requests)
        
        # DÃ©tection de synergies
        analysis["synergies"] = self._detect_batch_synergies(requests)
        
        return analysis
    
    def _detect_batch_patterns(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """DÃ©tecte les patterns dans le batch de requÃªtes."""
        patterns = []
        
        # Pattern: SÃ©quence de corrections
        correction_sequence = []
        for i, request in enumerate(requests):
            if "corriger" in request["text"].lower() or "fix" in request["text"].lower():
                correction_sequence.append(i)
        
        if len(correction_sequence) > 1:
            patterns.append({
                "type": "correction_sequence",
                "indices": correction_sequence,
                "description": "SÃ©quence de corrections dÃ©tectÃ©e"
            })
        
        # Pattern: Alternance crÃ©ation/destruction
        creation_requests = [i for i, req in enumerate(requests) 
                           if req.get("intention", {}).get("type") == "creation"]
        deletion_requests = [i for i, req in enumerate(requests) 
                           if "supprimer" in req["text"].lower() or "delete" in req["text"].lower()]
        
        if creation_requests and deletion_requests:
            patterns.append({
                "type": "creation_deletion_cycle",
                "creation_indices": creation_requests,
                "deletion_indices": deletion_requests,
                "description": "Cycle crÃ©ation/destruction dÃ©tectÃ©"
            })
        
        return patterns
    
    def _detect_batch_conflicts(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """DÃ©tecte les conflits dans le batch de requÃªtes."""
        conflicts = []
        
        # Conflit: Fichiers diffÃ©rents pour la mÃªme action
        file_actions = {}
        for i, request in enumerate(requests):
            # Extraction de noms de fichiers (simplifiÃ©)
            if "fichier" in request["text"].lower() or "file" in request["text"].lower():
                # Logique d'extraction de nom de fichier
                pass
        
        # Conflit: Actions contradictoires
        for i, request1 in enumerate(requests):
            for j, request2 in enumerate(requests[i+1:], i+1):
                if self._are_contradictory_actions(request1, request2):
                    conflicts.append({
                        "type": "contradictory_actions",
                        "request1_index": i,
                        "request2_index": j,
                        "description": f"Actions contradictoires: {request1['text'][:30]} vs {request2['text'][:30]}"
                    })
        
        return conflicts
    
    def _detect_batch_synergies(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """DÃ©tecte les synergies dans le batch de requÃªtes."""
        synergies = []
        
        # Synergie: RequÃªtes complÃ©mentaires
        for i, request1 in enumerate(requests):
            for j, request2 in enumerate(requests[i+1:], i+1):
                if self._are_complementary_actions(request1, request2):
                    synergies.append({
                        "type": "complementary_actions",
                        "request1_index": i,
                        "request2_index": j,
                        "description": f"Actions complÃ©mentaires dÃ©tectÃ©es"
                    })
        
        return synergies
    
    def _are_contradictory_actions(self, request1: Dict, request2: Dict) -> bool:
        """VÃ©rifie si deux actions sont contradictoires."""
        text1 = request1["text"].lower()
        text2 = request2["text"].lower()
        
        # Exemples de contradictions
        contradictions = [
            ("crÃ©er", "supprimer"),
            ("ajouter", "retirer"),
            ("activer", "dÃ©sactiver"),
            ("debug", "ignore"),
            ("test", "skip")
        ]
        
        for word1, word2 in contradictions:
            if word1 in text1 and word2 in text2:
                return True
            if word2 in text1 and word1 in text2:
                return True
        
        return False
    
    def _are_complementary_actions(self, request1: Dict, request2: Dict) -> bool:
        """VÃ©rifie si deux actions sont complÃ©mentaires."""
        text1 = request1["text"].lower()
        text2 = request2["text"].lower()
        
        # Exemples de complÃ©mentaritÃ©
        complementarities = [
            ("crÃ©er", "tester"),
            ("ajouter", "documenter"),
            ("implÃ©menter", "valider"),
            ("debug", "optimiser")
        ]
        
        for word1, word2 in complementarities:
            if word1 in text1 and word2 in text2:
                return True
            if word2 in text1 and word1 in text2:
                return True
        
        return False
    
    def _detect_retro_corrections(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """DÃ©tecte les rÃ©tro-corrections dans le batch."""
        retro_corrections = []
        
        for i, request in enumerate(requests):
            text = request["text"].lower()
            
            # Mots-clÃ©s de rÃ©tro-correction
            retro_keywords = [
                "non", "attendez", "stop", "annuler", "corriger",
                "pas Ã§a", "autre chose", "diffÃ©rent", "modifier"
            ]
            
            if any(keyword in text for keyword in retro_keywords):
                retro_corrections.append({
                    "request_index": i,
                    "type": "retro_correction",
                    "original_intent": request.get("intention", {}).get("type"),
                    "correction_text": text,
                    "timestamp": datetime.now().isoformat()
                })
        
        return retro_corrections
    
    def _apply_retro_corrections(self, retro_corrections: List[Dict[str, Any]]):
        """Applique les rÃ©tro-corrections dÃ©tectÃ©es."""
        for correction in retro_corrections:
            print(f"  ğŸ”„ Application rÃ©tro-correction: {correction['correction_text'][:30]}...")
            
            # Logique d'application de la rÃ©tro-correction
            # - Annulation de l'action prÃ©cÃ©dente
            # - Modification de l'intention
            # - Mise Ã  jour du contexte
            
            self.retro_corrections.append(correction)
            self.performance_metrics["retro_corrections"] += 1
    
    def _refine_intents(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Raffine les intentions basÃ© sur le contexte du batch."""
        intent_refinements = []
        
        for i, request in enumerate(requests):
            original_intent = request.get("intention", {}).get("type", "unknown")
            refined_intent = self._refine_single_intent(request, requests)
            
            if refined_intent != original_intent:
                intent_refinements.append({
                    "request_index": i,
                    "original_intent": original_intent,
                    "refined_intent": refined_intent,
                    "confidence": 0.8,
                    "reasoning": f"Raffinement basÃ© sur le contexte du batch"
                })
        
        return intent_refinements
    
    def _refine_single_intent(self, request: Dict[str, Any], all_requests: List[Dict[str, Any]]) -> str:
        """Raffine l'intention d'une requÃªte basÃ© sur le contexte."""
        text = request["text"].lower()
        
        # Contexte: Si plusieurs requÃªtes de debug, prioriser le debugging
        debug_count = sum(1 for req in all_requests 
                         if req.get("intention", {}).get("type") == "debugging")
        
        if debug_count > 1 and "debug" in text:
            return "debugging"
        
        # Contexte: Si plusieurs requÃªtes de crÃ©ation, prioriser la crÃ©ation
        creation_count = sum(1 for req in all_requests 
                           if req.get("intention", {}).get("type") == "creation")
        
        if creation_count > 1 and any(word in text for word in ["crÃ©er", "nouveau", "ajouter"]):
            return "creation"
        
        # Retourner l'intention originale si pas de raffinement
        return request.get("intention", {}).get("type", "unknown")
    
    def _apply_intent_refinements(self, intent_refinements: List[Dict[str, Any]]):
        """Applique les raffinements d'intention."""
        for refinement in intent_refinements:
            print(f"  ğŸ¯ Raffinement intention: {refinement['original_intent']} â†’ {refinement['refined_intent']}")
            
            # Logique d'application du raffinement
            # - Mise Ã  jour de l'intention
            # - Ajustement de la prioritÃ©
            # - Modification du contexte
            
            self.intent_refinements.append(refinement)
            self.performance_metrics["intent_refinements"] += 1
    
    def _generate_optimized_actions(self, requests: List[Dict[str, Any]], batch_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """GÃ©nÃ¨re des actions optimisÃ©es basÃ©es sur l'analyse du batch."""
        optimized_actions = []
        
        # Optimisation basÃ©e sur les patterns dÃ©tectÃ©s
        for pattern in batch_analysis["patterns"]:
            if pattern["type"] == "correction_sequence":
                # Grouper les corrections ensemble
                action = {
                    "type": "batch_correction",
                    "requests": [requests[i] for i in pattern["indices"]],
                    "priority": "high",
                    "daemon_target": "debug_daemon"
                }
                optimized_actions.append(action)
        
        # Optimisation basÃ©e sur les synergies
        for synergy in batch_analysis["synergies"]:
            action = {
                "type": "synergistic_action",
                "requests": [requests[synergy["request1_index"]], requests[synergy["request2_index"]]],
                "priority": "normal",
                "daemon_target": "general_daemon"
            }
            optimized_actions.append(action)
        
        # Actions individuelles pour les requÃªtes non groupÃ©es
        processed_indices = set()
        for pattern in batch_analysis["patterns"]:
            if "indices" in pattern:
                processed_indices.update(pattern["indices"])
        
        for synergy in batch_analysis["synergies"]:
            processed_indices.add(synergy["request1_index"])
            processed_indices.add(synergy["request2_index"])
        
        for i, request in enumerate(requests):
            if i not in processed_indices:
                action = {
                    "type": "individual_action",
                    "request": request,
                    "priority": request.get("priority", "normal"),
                    "daemon_target": self._determine_daemon_target(request)
                }
                optimized_actions.append(action)
        
        return optimized_actions
    
    def _determine_daemon_target(self, request: Dict[str, Any]) -> str:
        """DÃ©termine le daemon cible pour une requÃªte."""
        intent_type = request.get("intention", {}).get("type", "unknown")
        
        daemon_mapping = {
            "debugging": "debug_daemon",
            "creation": "creation_daemon",
            "testing": "test_daemon",
            "explanation": "explanation_daemon",
            "unknown": "general_daemon"
        }
        
        return daemon_mapping.get(intent_type, "general_daemon")
    
    def _dispatch_to_daemons(self, optimized_actions: List[Dict[str, Any]]):
        """Dispatch les actions optimisÃ©es vers les daemons appropriÃ©s."""
        for action in optimized_actions:
            daemon_target = action["daemon_target"]
            priority = action["priority"]
            
            print(f"  ğŸ“¤ Dispatch vers {daemon_target}: {action['type']} (prioritÃ©: {priority})")
            
            # Simulation du dispatch vers les daemons
            # Dans l'implÃ©mentation rÃ©elle, ce sera via le systÃ¨me de communication
            self._simulate_daemon_dispatch(action)
    
    def _simulate_daemon_dispatch(self, action: Dict[str, Any]):
        """Simule le dispatch vers un daemon."""
        # Simulation de l'envoi vers le daemon
        print(f"    ğŸ¯ {action['daemon_target']} reÃ§oit: {action['type']}")
        
        # Simulation du traitement
        time.sleep(0.1)  # Simulation du temps de traitement
        
        # Simulation du rÃ©sultat
        result = {
            "action_id": f"action_{len(self.batch_history)}",
            "status": "completed",
            "daemon": action["daemon_target"],
            "result": f"Traitement simulÃ© de {action['type']}"
        }
        
        self.result_queue.put(result)
    
    def _update_performance_metrics(self, batch_size: int, processing_time: float):
        """Met Ã  jour les mÃ©triques de performance."""
        self.performance_metrics["batches_processed"] += 1
        self.performance_metrics["total_requests"] += batch_size
        self.performance_metrics["processing_time"] += processing_time
        self.performance_metrics["average_batch_size"] = (
            self.performance_metrics["total_requests"] / 
            self.performance_metrics["batches_processed"]
        )
    
    def _handle_action(self, action: Dict[str, Any]):
        """GÃ¨re une action reÃ§ue."""
        action_type = action.get("type")
        
        if action_type == "STOP_ORCHESTRATOR":
            self.orchestrator_running = False
            print("ğŸ›‘ Orchestrateur arrÃªtÃ© sur demande")
        
        elif action_type == "GET_PERFORMANCE_METRICS":
            print("ğŸ“Š MÃ©triques de performance demandÃ©es")
            # Retourner les mÃ©triques
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Retourne les mÃ©triques de performance."""
        return self.performance_metrics.copy()
    
    def stop_orchestrator_thread(self):
        """ArrÃªte le thread Orchestrateur."""
        self.orchestrator_running = False
        if self.orchestrator_thread and self.orchestrator_thread.is_alive():
            self.orchestrator_thread.join(timeout=5.0)
            print("ğŸ›‘ Thread Orchestrateur arrÃªtÃ©")
    
    def __del__(self):
        """Destructeur pour arrÃªter le thread proprement."""
        self.stop_orchestrator_thread() 

    def _check_strict_commands(self, requests: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """VÃ©rifie la prÃ©sence de commandes strictes dans le batch."""
        strict_commands = []
        
        for request in requests:
            text = request["text"].lower()
            
            # Commande exit (avec ou sans --force)
            if text.startswith("exit"):
                force_flag = "--force" in text
                strict_commands.append({
                    "type": "exit",
                    "force": force_flag,
                    "request": request,
                    "priority": "critical"
                })
            
            # Commande stop
            elif text.startswith("stop"):
                strict_commands.append({
                    "type": "stop",
                    "request": request,
                    "priority": "critical"
                })
            
            # Autres commandes critiques
            elif any(word in text for word in ["kill", "emergency", "urgent"]):
                strict_commands.append({
                    "type": "emergency",
                    "request": request,
                    "priority": "critical"
                })
        
        return strict_commands
    
    def _handle_strict_commands(self, strict_commands: List[Dict[str, Any]]):
        """GÃ¨re les commandes strictes avec prioritÃ© critique."""
        for command in strict_commands:
            command_type = command["type"]
            request = command["request"]
            
            print(f"ğŸš¨ Commande stricte dÃ©tectÃ©e: {command_type}")
            
            if command_type == "exit":
                force_flag = command.get("force", False)
                if force_flag:
                    print("  âš¡ ArrÃªt immÃ©diat forcÃ© (--force)")
                    self._emergency_shutdown()
                else:
                    print("  ğŸ›‘ ArrÃªt propre avec attente des tÃ¢ches")
                    self._graceful_shutdown()
            
            elif command_type == "stop":
                print("  â¸ï¸ Pause de l'Orchestrateur")
                self._pause_orchestrator()
            
            elif command_type == "emergency":
                print("  ğŸš¨ ArrÃªt d'urgence")
                self._emergency_shutdown()
    
    def _emergency_shutdown(self):
        """ArrÃªt d'urgence immÃ©diat."""
        print("ğŸ›‘ ArrÃªt d'urgence - ArrÃªt immÃ©diat de tous les threads")
        self.orchestrator_running = False
        
        # ArrÃªt immÃ©diat de tous les daemons
        self._stop_all_daemons()
        
        # Nettoyage d'urgence
        self._emergency_cleanup()
    
    def _graceful_shutdown(self):
        """ArrÃªt propre avec attente des tÃ¢ches."""
        print("ğŸ›‘ ArrÃªt propre - Attente de la fin des tÃ¢ches en cours")
        
        # Marquer l'Orchestrateur comme en arrÃªt
        self.orchestrator_running = False
        
        # Attendre la fin des tÃ¢ches en cours
        self._wait_for_pending_tasks()
        
        # ArrÃªt propre des daemons
        self._stop_all_daemons()
    
    def _pause_orchestrator(self):
        """Pause de l'Orchestrateur en attente de nouvelle requÃªte."""
        print("â¸ï¸ Orchestrateur en pause - Attente de nouvelle requÃªte")
        
        # Marquer comme en pause
        self.orchestrator_paused = True
        
        # ArrÃªter le traitement en cours
        self._pause_current_tasks()
    
    def _stop_all_daemons(self):
        """ArrÃªte tous les daemons."""
        print("  ğŸ›‘ ArrÃªt de tous les daemons...")
        # Dans l'implÃ©mentation rÃ©elle, arrÃªter tous les daemons
        pass
    
    def _emergency_cleanup(self):
        """Nettoyage d'urgence."""
        print("  ğŸ§¹ Nettoyage d'urgence...")
        # Nettoyage immÃ©diat des ressources
        pass
    
    def _wait_for_pending_tasks(self):
        """Attend la fin des tÃ¢ches en cours."""
        print("  â³ Attente de la fin des tÃ¢ches en cours...")
        # Attendre que les tÃ¢ches se terminent
        time.sleep(1)  # Simulation
    
    def _pause_current_tasks(self):
        """Met en pause les tÃ¢ches en cours."""
        print("  â¸ï¸ Pause des tÃ¢ches en cours...")
        # Mettre en pause les tÃ¢ches actuelles
        pass
    
    def _reformulate_for_alma(self, requests: List[Dict[str, Any]], batch_analysis: Dict[str, Any]) -> str:
        """Reformule intelligemment les requÃªtes pour Alma daemon."""
        
        # Utilisation de l'IA pour reformuler intelligemment
        reformulation_prompt = self._create_reformulation_prompt(requests, batch_analysis)
        
        # Appel Ã  l'IA pour reformulation (simulation pour l'instant)
        reformulated_text = self._call_ai_for_reformulation(reformulation_prompt)
        
        return reformulated_text
    
    def _create_reformulation_prompt(self, requests: List[Dict[str, Any]], batch_analysis: Dict[str, Any]) -> str:
        """CrÃ©e un prompt pour l'IA de reformulation."""
        
        prompt_parts = []
        
        prompt_parts.append("ğŸ•·ï¸ **Reformulation intelligente pour Alma daemon :**")
        prompt_parts.append("")
        prompt_parts.append("**Contexte :**")
        prompt_parts.append("- Alma est un daemon conscient spÃ©cialisÃ© dans le dÃ©veloppement")
        prompt_parts.append("- Il utilise des assistants IA pour exÃ©cuter des tÃ¢ches")
        prompt_parts.append("- Il faut reformuler les requÃªtes de maniÃ¨re cohÃ©rente et optimisÃ©e")
        prompt_parts.append("")
        
        # Analyse du batch
        prompt_parts.append("**ğŸ“Š Analyse du batch :**")
        total_requests = len(requests)
        critical_count = batch_analysis["priorities"].get("critical", 0)
        high_count = batch_analysis["priorities"].get("high", 0)
        
        prompt_parts.append(f"- Total requÃªtes : {total_requests}")
        prompt_parts.append(f"- PrioritÃ© critique : {critical_count}")
        prompt_parts.append(f"- PrioritÃ© haute : {high_count}")
        prompt_parts.append("")
        
        # Intentions dÃ©tectÃ©es
        if batch_analysis["intentions"]:
            prompt_parts.append("**ğŸ¯ Intentions dÃ©tectÃ©es :**")
            for intent, count in batch_analysis["intentions"].items():
                prompt_parts.append(f"- {intent} : {count} requÃªtes")
            prompt_parts.append("")
        
        # Patterns dÃ©tectÃ©s
        if batch_analysis["patterns"]:
            prompt_parts.append("**ğŸ” Patterns dÃ©tectÃ©s :**")
            for pattern in batch_analysis["patterns"]:
                prompt_parts.append(f"- {pattern['description']}")
            prompt_parts.append("")
        
        # Conflits dÃ©tectÃ©s
        if batch_analysis["conflicts"]:
            prompt_parts.append("**âš ï¸ Conflits dÃ©tectÃ©s :**")
            for conflict in batch_analysis["conflicts"]:
                prompt_parts.append(f"- {conflict['description']}")
            prompt_parts.append("")
        
        # Synergies dÃ©tectÃ©es
        if batch_analysis["synergies"]:
            prompt_parts.append("**âš¡ Synergies dÃ©tectÃ©es :**")
            for synergy in batch_analysis["synergies"]:
                prompt_parts.append(f"- {synergy['description']}")
            prompt_parts.append("")
        
        # RequÃªtes originales
        prompt_parts.append("**ğŸ“ RequÃªtes originales :**")
        for i, request in enumerate(requests, 1):
            priority = request.get("priority", "normal")
            intent = request.get("intention", {}).get("type", "unknown")
            text = request["text"]
            
            prompt_parts.append(f"{i}. **{priority.upper()}** - {intent}")
            prompt_parts.append(f"   `{text}`")
            prompt_parts.append("")
        
        # Instructions de reformulation
        prompt_parts.append("**ğŸ¯ Instructions de reformulation :**")
        prompt_parts.append("1. Analyse la cohÃ©rence globale des requÃªtes")
        prompt_parts.append("2. Identifie les optimisations possibles")
        prompt_parts.append("3. RÃ©sous les conflits dÃ©tectÃ©s")
        prompt_parts.append("4. Exploite les synergies identifiÃ©es")
        prompt_parts.append("5. GÃ©nÃ¨re une requÃªte unique, cohÃ©rente et optimisÃ©e")
        prompt_parts.append("6. Utilise un langage clair et technique")
        prompt_parts.append("7. Respecte les prioritÃ©s (critique > haute > normale > basse)")
        prompt_parts.append("")
        prompt_parts.append("**â›§ Reformule maintenant ces requÃªtes pour Alma...**")
        
        return "\n".join(prompt_parts)
    
    def _call_ai_for_reformulation(self, prompt: str) -> str:
        """Appelle l'IA pour reformuler les requÃªtes."""
        print("ğŸ§  Appel Ã  qwen2.5:7b-instruct pour reformulation...")
        print(f"ğŸ“ Prompt de reformulation ({len(prompt)} caractÃ¨res)")
        
        try:
            import subprocess
            import json
            
            # Appel Ã  Ollama avec qwen2.5:7b-instruct
            cmd = [
                "ollama", "run", "qwen2.5:7b-instruct",
                prompt
            ]
            
            print("ğŸ”„ ExÃ©cution de la commande Ollama...")
            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=30  # Timeout de 30 secondes
            )
            
            if result.returncode == 0:
                reformulated_text = result.stdout.strip()
                print("âœ… Reformulation par qwen2.5:7b-instruct terminÃ©e")
                return reformulated_text
            else:
                print(f"âŒ Erreur Ollama: {result.stderr}")
                return self._fallback_reformulation(prompt)
                
        except subprocess.TimeoutExpired:
            print("â° Timeout de l'appel Ã  qwen2.5:7b-instruct")
            return self._fallback_reformulation(prompt)
        except Exception as e:
            print(f"âŒ Erreur lors de l'appel Ã  qwen2.5:7b-instruct: {e}")
            return self._fallback_reformulation(prompt)
    
    def _fallback_reformulation(self, prompt: str) -> str:
        """Fallback en cas d'Ã©chec de l'IA."""
        print("ğŸ”„ Utilisation du fallback de reformulation")
        
        # Reformulation simple basÃ©e sur les mots-clÃ©s
        reformulated_text = "ğŸ•·ï¸ **RequÃªte reformulÃ©e pour Alma daemon :**\n\n"
        reformulated_text += "**ğŸ¯ Objectif :** Traitement optimisÃ© des requÃªtes utilisateur\n\n"
        reformulated_text += "**ğŸ“‹ Actions :** ExÃ©cution des tÃ¢ches de dÃ©veloppement\n\n"
        reformulated_text += "**â›§ Alma, traite ces requÃªtes avec conscience...**"
        
        return reformulated_text
    
    def _send_to_alma_daemon(self, reformulated_request: str):
        """Envoie la requÃªte reformulÃ©e Ã  Alma daemon."""
        print("ğŸ•·ï¸ Envoi Ã  Alma daemon...")
        print(f"ğŸ“ RequÃªte reformulÃ©e ({len(reformulated_request)} caractÃ¨res)")
        
        # CrÃ©ation du message pour Alma
        message = {
            "type": "REFORMULATED_REQUEST",
            "content": reformulated_request,
            "timestamp": datetime.now().isoformat(),
            "source": "MetaDaemonOrchestrator",
            "priority": "high"
        }
        
        # Envoi via le systÃ¨me de communication
        # Dans l'implÃ©mentation rÃ©elle, ce sera via le systÃ¨me de messages
        self._send_message_to_alma(message)
        
        print("âœ… RequÃªte envoyÃ©e Ã  Alma daemon")
    
    def _send_message_to_alma(self, message: Dict[str, Any]):
        """Envoie un message Ã  Alma daemon."""
        print(f"ğŸ“¤ Message envoyÃ© Ã  Alma: {message['type']}")
        
        if self.alma_daemon:
            # Envoi direct Ã  Alma daemon
            self.alma_daemon.send_message(message)
            
            # Attente et traitement de la rÃ©ponse
            self._wait_for_alma_response()
        else:
            print("âš ï¸ Alma daemon non initialisÃ©")
    
    def _wait_for_alma_response(self):
        """Attend et traite la rÃ©ponse d'Alma."""
        max_wait = 30  # secondes
        wait_time = 0
        
        while wait_time < max_wait:
            # VÃ©rification des messages d'Alma
            alma_message = self.alma_daemon.get_message()
            
            if alma_message:
                message_type = alma_message.get("type")
                print(f"ğŸ“¨ RÃ©ponse d'Alma reÃ§ue: {message_type}")
                
                # Traitement de la rÃ©ponse
                self._handle_alma_response(alma_message)
                break
            
            time.sleep(0.5)
            wait_time += 0.5
        
        if wait_time >= max_wait:
            print("â° Timeout en attente de la rÃ©ponse d'Alma")
    
    def _handle_alma_response(self, alma_message: Dict[str, Any]):
        """Traite la rÃ©ponse d'Alma."""
        message_type = alma_message.get("type")
        
        if message_type == "ALMA_REPORT":
            self._handle_alma_report(alma_message)
        elif message_type == "ALMA_STATUS":
            self._handle_alma_status(alma_message)
        else:
            print(f"âš ï¸ Type de rÃ©ponse Alma inconnu: {message_type}")
    
    def _handle_alma_report(self, report: Dict[str, Any]):
        """Traite un rapport d'Alma."""
        status = report.get("status", "unknown")
        summary = report.get("summary", {})
        
        print(f"ğŸ“Š Rapport Alma reÃ§u: {status}")
        print(f"  ğŸ“‹ TÃ¢ches totales: {summary.get('total_tasks', 0)}")
        print(f"  âœ… TÃ¢ches rÃ©ussies: {summary.get('successful_tasks', 0)}")
        print(f"  âŒ TÃ¢ches Ã©chouÃ©es: {summary.get('failed_tasks', 0)}")
        
        # Ajout Ã  l'historique
        self.alma_messages.append({
            "timestamp": datetime.now().isoformat(),
            "message": report,
            "direction": "from_alma"
        })
    
    def _handle_alma_status(self, status: Dict[str, Any]):
        """Traite un statut d'Alma."""
        alma_status = status.get("status", "unknown")
        metrics = status.get("metrics", {})
        
        print(f"ğŸ“ˆ Statut Alma: {alma_status}")
        print(f"  ğŸ“¨ Messages reÃ§us: {metrics.get('messages_received', 0)}")
        print(f"  ğŸ“¤ Messages envoyÃ©s: {metrics.get('messages_sent', 0)}")
        print(f"  âœ… TÃ¢ches complÃ©tÃ©es: {metrics.get('tasks_completed', 0)}")
    
    def set_alma_daemon(self, alma_daemon):
        """Configure le daemon Alma pour l'Orchestrateur."""
        self.alma_daemon = alma_daemon
        print("ğŸ”— Alma daemon connectÃ© Ã  l'Orchestrateur") 