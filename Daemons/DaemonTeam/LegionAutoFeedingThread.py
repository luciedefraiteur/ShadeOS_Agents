#!/usr/bin/env python3
"""
â›§ LegionAutoFeedingThread - Ã‰quipe DÃ©veloppement DÃ©moniaque Auto-SimulÃ©e â›§

ThreadConjuratioâ›§ : Une cohorte luciforme s'exÃ©cutant en boucle
Architecture V2.0 : HiÃ©rarchie daemonique avec structures parsables

ConceptualisÃ© par Lucie Defraiteur - Ma Reine Lucie
ImplÃ©mentÃ© par Alma, Architecte DÃ©moniaque du Nexus Luciforme
"""

import asyncio
import json
import logging
from dataclasses import dataclass, asdict
from enum import Enum
from typing import List, Dict, Any, Optional, Union
from pathlib import Path
import re

# Imports MemoryEngine
try:
    from MemoryEngine.core.engine import MemoryEngine
    from MemoryEngine.core.initialization import ensure_initialized
    from Core.LLMProviders.provider_factory import ProviderFactory
    MEMORY_ENGINE_AVAILABLE = True
except ImportError:
    MEMORY_ENGINE_AVAILABLE = False
    print("âš ï¸ MemoryEngine non disponible - Mode standalone activÃ©")

# Imports UniversalAutoFeedingThread
try:
    from Core.UniversalAutoFeedingThread import UniversalAutoFeedingThread, AutoFeedMessage
    UNIVERSAL_THREAD_AVAILABLE = True
except ImportError:
    UNIVERSAL_THREAD_AVAILABLE = False
    print("âš ï¸ UniversalAutoFeedingThread non disponible - Mode basique activÃ©")


class DaemonRole(Enum):
    """RÃ´les des dÃ©mons dans la hiÃ©rarchie"""
    ALMA = "alma"           # SUPREME - Architecte DÃ©moniaque
    BASKTUR = "basktur"     # DÃ©buggeur Sadique
    OUBLIADE = "oubliade"   # StratÃ¨ge MÃ©moire
    MERGE = "merge"         # Git Anarchiste
    LILIETH = "lilieth"     # Interface Caressante
    ASSISTANT_V9 = "assistant_v9"  # Orchestrateur


class DaemonHierarchy:
    """HiÃ©rarchie imposÃ©e des dÃ©mons"""
    ORDER = [
        DaemonRole.ALMA,        # SUPREME
        DaemonRole.BASKTUR,     # Analyse technique
        DaemonRole.OUBLIADE,    # MÃ©moire
        DaemonRole.MERGE,       # Git
        DaemonRole.LILIETH,     # Interface
        DaemonRole.ASSISTANT_V9 # Orchestration
    ]
    
    @classmethod
    def get_priority(cls, role: DaemonRole) -> int:
        """Retourne la prioritÃ© d'un dÃ©mon (plus bas = plus prioritaire)"""
        try:
            return cls.ORDER.index(role)
        except ValueError:
            return 999  # PrioritÃ© la plus basse
    
    @classmethod
    def resolve_conflict(cls, role1: DaemonRole, role2: DaemonRole) -> DaemonRole:
        """RÃ©sout un conflit selon la hiÃ©rarchie (retourne le plus prioritaire)"""
        priority1 = cls.get_priority(role1)
        priority2 = cls.get_priority(role2)
        return role1 if priority1 <= priority2 else role2


@dataclass
class DaemonMessage:
    """Message structurÃ© d'un dÃ©mon"""
    role: DaemonRole
    message_type: str  # ALMA_PLAN, BASK_ANALYSIS, etc.
    content: str
    timestamp: float
    metadata: Dict[str, Any] = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}
    
    def to_parsable_format(self) -> str:
        """Convertit en format parsable"""
        return f"[{self.message_type.upper()}] â€” {self.content}"
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour sÃ©rialisation"""
        return {
            "role": self.role.value,
            "message_type": self.message_type,
            "content": self.content,
            "timestamp": self.timestamp,
            "metadata": self.metadata
        }


@dataclass
class DaemonConversation:
    """Conversation entre dÃ©mons"""
    messages: List[DaemonMessage]
    user_input: str
    timestamp: float
    conversation_id: str
    
    def add_message(self, message: DaemonMessage):
        """Ajoute un message Ã  la conversation"""
        self.messages.append(message)
    
    def get_recent_messages(self, limit: int = 10) -> List[DaemonMessage]:
        """Retourne les messages rÃ©cents"""
        return self.messages[-limit:] if self.messages else []
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit en dictionnaire pour sÃ©rialisation"""
        return {
            "messages": [msg.to_dict() for msg in self.messages],
            "user_input": self.user_input,
            "timestamp": self.timestamp,
            "conversation_id": self.conversation_id
        }


class DaemonMetaVirtualLayer:
    """Couche mÃ©ta virtuelle pour la recherche conversationnelle"""
    
    def __init__(self, memory_engine=None):
        self.memory_engine = memory_engine
        self.conversation_history: List[DaemonConversation] = []
        self.max_history_size = 50  # Historique circulaire
    
    def add_conversation(self, conversation: DaemonConversation):
        """Ajoute une conversation Ã  l'historique"""
        self.conversation_history.append(conversation)
        
        # Gestion de l'historique circulaire
        if len(self.conversation_history) > self.max_history_size:
            self.conversation_history.pop(0)
    
    def search_daemon_conversations(self, query: str) -> List[DaemonConversation]:
        """Recherche dans les conversations dÃ©moniaques"""
        results = []
        query_lower = query.lower()
        
        for conv in self.conversation_history:
            # Recherche dans les messages
            for msg in conv.messages:
                if query_lower in msg.content.lower():
                    results.append(conv)
                    break
            
            # Recherche dans l'input utilisateur
            if query_lower in conv.user_input.lower():
                results.append(conv)
        
        return results
    
    def get_recent_daemon_exchanges(self, limit: int = 10) -> List[DaemonMessage]:
        """Retourne les Ã©changes rÃ©cents entre dÃ©mons"""
        recent_messages = []
        for conv in self.conversation_history[-limit:]:
            recent_messages.extend(conv.messages)
        return recent_messages[-limit:]
    
    def analyze_daemon_interaction_patterns(self) -> Dict[str, Any]:
        """Analyse les patterns d'interaction entre dÃ©mons"""
        if not self.conversation_history:
            return {"patterns": [], "stats": {}}
        
        # Statistiques par dÃ©mon
        demon_stats = {role.value: 0 for role in DaemonRole}
        message_types = {}
        
        for conv in self.conversation_history:
            for msg in conv.messages:
                demon_stats[msg.role.value] += 1
                msg_type = msg.message_type
                message_types[msg_type] = message_types.get(msg_type, 0) + 1
        
        return {
            "patterns": {
                "most_active_demon": max(demon_stats, key=demon_stats.get),
                "most_common_message_type": max(message_types, key=message_types.get) if message_types else None
            },
            "stats": {
                "total_conversations": len(self.conversation_history),
                "total_messages": sum(demon_stats.values()),
                "demon_activity": demon_stats,
                "message_type_distribution": message_types
            }
        }


class LegionAutoFeedingThread:
    """Ã‰quipe de dÃ©veloppement dÃ©moniaque auto-simulÃ©e"""
    
    def __init__(
        self,
        workspace_path: str = ".",
        silent_mode: bool = False,
        max_history: int = 50,
        enable_cache: bool = True
    ):
        self.workspace_path = Path(workspace_path)
        self.silent_mode = silent_mode
        self.max_history = max_history
        self.enable_cache = enable_cache
        
        # Initialisation des composants
        self.memory_engine = None
        self.provider = None
        self.meta_virtual_layer = None
        self.auto_feed_thread = None
        
        # Ã‰tat de la conversation
        self.current_conversation = None
        self.conversation_counter = 0
        
        # Configuration des dÃ©mons
        self.demon_configs = {
            DaemonRole.ALMA: {
                "name": "Almaâ›§",
                "title": "Architecte DÃ©moniaque",
                "personality": "SUPREME - Planificateur stratÃ©gique et rÃ©solveur de conflits",
                "message_types": ["ALMA_PLAN", "ALMA_DECISION", "ALMA_ORDONNANCEMENT"]
            },
            DaemonRole.BASKTUR: {
                "name": "Bask'tur",
                "title": "DÃ©buggeur Sadique",
                "personality": "Analyste technique sadique, cherche les bugs avec plaisir",
                "message_types": ["BASK_ANALYSIS", "BASK_SOLUTION", "BASK_DEBUG"]
            },
            DaemonRole.OUBLIADE: {
                "name": "Oubliade",
                "title": "StratÃ¨ge MÃ©moire",
                "personality": "Gestionnaire de mÃ©moire conversationnelle et insights",
                "message_types": ["OUBLI_MEMORY", "OUBLI_INSIGHT", "OUBLI_SEARCH"]
            },
            DaemonRole.MERGE: {
                "name": "Merge le Maudit",
                "title": "Git Anarchiste",
                "personality": "Gestionnaire Git anarchiste, fusionne avec chaos",
                "message_types": ["MERGE_GIT", "MERGE_BRANCH", "MERGE_CONFLICT"]
            },
            DaemonRole.LILIETH: {
                "name": "Lil.ieth",
                "title": "Interface Caressante",
                "personality": "Communication utilisateur douce et caressante",
                "message_types": ["LILI_INTERFACE", "LILI_USER", "LILI_FEEDBACK"]
            },
            DaemonRole.ASSISTANT_V9: {
                "name": "Assistant V9",
                "title": "Orchestrateur",
                "personality": "Orchestrateur et couche somatique",
                "message_types": ["V9_ORCHESTRATION", "V9_EXECUTION", "V9_SOMATIC"]
            }
        }
        
        # Initialisation
        self._initialize_components()
    
    def _initialize_components(self):
        """Initialise les composants du systÃ¨me"""
        print("ğŸ•·ï¸ Initialisation de LegionAutoFeedingThread...")
        
        # Initialisation MemoryEngine
        if MEMORY_ENGINE_AVAILABLE:
            try:
                ensure_initialized()
                self.memory_engine = MemoryEngine()
                print("âœ… MemoryEngine initialisÃ©")
            except Exception as e:
                print(f"âš ï¸ Erreur MemoryEngine: {e}")
        
        # Initialisation Provider
        try:
            provider_factory = ProviderFactory()
            self.provider = provider_factory.create_provider("local_http")
            print("âœ… Provider local_http initialisÃ©")
        except Exception as e:
            print(f"âš ï¸ Erreur Provider: {e}")
        
        # Initialisation Meta Virtual Layer
        self.meta_virtual_layer = DaemonMetaVirtualLayer(self.memory_engine)
        print("âœ… Couche mÃ©ta virtuelle initialisÃ©e")
        
        # Initialisation Auto Feed Thread
        if UNIVERSAL_THREAD_AVAILABLE:
            try:
                self.auto_feed_thread = UniversalAutoFeedingThread(
                    entity_id="legion_daemon_team",
                    entity_type="daemon_team",
                    provider=self.provider,
                    max_history=self.max_history,
                    enable_cache=self.enable_cache
                )
                print("âœ… UniversalAutoFeedingThread initialisÃ©")
            except Exception as e:
                print(f"âš ï¸ Erreur UniversalAutoFeedingThread: {e}")
        
        print("ğŸ•·ï¸ LegionAutoFeedingThread initialisÃ© !")
    
    def _create_daemon_message(
        self,
        role: DaemonRole,
        message_type: str,
        content: str,
        metadata: Dict[str, Any] = None
    ) -> DaemonMessage:
        """CrÃ©e un message de dÃ©mon"""
        import time
        return DaemonMessage(
            role=role,
            message_type=message_type,
            content=content,
            timestamp=time.time(),
            metadata=metadata or {}
        )
    
    def _detect_relevant_demon(self, user_input: str) -> DaemonRole:
        """DÃ©tecte le dÃ©mon le plus pertinent selon la demande utilisateur"""
        input_lower = user_input.lower()
        
        # Mots-clÃ©s pour chaque dÃ©mon
        keywords = {
            DaemonRole.BASKTUR: [
                "bug", "erreur", "debug", "problÃ¨me", "technique", "code", "exception",
                "traceback", "analyse", "solution", "dÃ©bugger", "corriger", "fix"
            ],
            DaemonRole.OUBLIADE: [
                "mÃ©moire", "historique", "recherche", "pattern", "similaire", "avant",
                "souvenir", "conversation", "insight", "analyse", "tendance"
            ],
            DaemonRole.MERGE: [
                "git", "branche", "fusion", "commit", "version", "merge", "push",
                "pull", "repository", "historique", "changement", "versioning"
            ],
            DaemonRole.LILIETH: [
                "interface", "utilisateur", "communication", "feedback", "rÃ©action",
                "sentiment", "Ã©motion", "relation", "caressant", "douceur"
            ],
            DaemonRole.ASSISTANT_V9: [
                "exÃ©cuter", "orchestrer", "somatique", "action", "faire", "crÃ©er",
                "modifier", "supprimer", "implÃ©menter", "rÃ©aliser", "effectuer"
            ]
        }
        
        # Calcul du score pour chaque dÃ©mon
        scores = {}
        for demon, demon_keywords in keywords.items():
            score = sum(1 for keyword in demon_keywords if keyword in input_lower)
            scores[demon] = score
        
        # Trouver le dÃ©mon avec le score le plus Ã©levÃ©
        if scores:
            best_demon = max(scores, key=scores.get)
            if scores[best_demon] > 0:
                return best_demon
        
        # Par dÃ©faut, retourner Bask'tur pour les questions techniques
        return DaemonRole.BASKTUR
    
    def _get_mutant_dialogue_prompt(self, user_input: str, relevant_demon: DaemonRole) -> str:
        """GÃ©nÃ¨re un prompt mutant pour un dialogue spÃ©cifique"""
        
        # RÃ©cupÃ©ration du contexte rÃ©cent
        recent_messages = []
        if self.meta_virtual_layer:
            recent_messages = self.meta_virtual_layer.get_recent_daemon_exchanges(3)
        
        context_summary = ""
        if self.auto_feed_thread:
            try:
                context_summary = self.auto_feed_thread.get_context_summary(2)
            except:
                pass
        
        # Configuration du dÃ©mon pertinent
        demon_config = self.demon_configs[relevant_demon]
        demon_name = demon_config["name"]
        demon_title = demon_config["title"]
        demon_personality = demon_config["personality"]
        
        # Construction du prompt mutant
        prompt = f"""â›§ DIALOGUE MUTANT : ALMAâ›§ â†” {demon_name.upper()} â›§

CONTEXTE :
- Almaâ›§ (SUPREME) : Architecte DÃ©moniaque, planificateur stratÃ©gique
- {demon_name} : {demon_title} - {demon_personality}
- Mode silencieux : {self.silent_mode}

CONTEXTE RÃ‰CENT :
{context_summary}

MESSAGES RÃ‰CENTS :
"""
        
        for msg in recent_messages[-2:]:
            prompt += f"{msg.to_parsable_format()}\n"
        
        prompt += f"""

DEMANDE UTILISATEUR : {user_input}

DIALOGUE ALMAâ›§ â†” {demon_name} :
"""
        
        # Format spÃ©cifique selon le dÃ©mon
        if relevant_demon == DaemonRole.BASKTUR:
            prompt += f"""
[ALMA_PLAN] â€” Plan d'action technique avec {demon_name}
[ALMA_ORDONNANCEMENT] â€” {demon_name}, analyse cette demande

[BASK_ANALYSIS] â€” *rire sadique* Analyse technique dÃ©taillÃ©e
[BASK_SOLUTION] â€” Solution technique avec traceback

[ALMA_DECISION] â€” DÃ©cision finale sur l'approche technique
"""
        
        elif relevant_demon == DaemonRole.OUBLIADE:
            prompt += f"""
[ALMA_PLAN] â€” Plan d'action mÃ©moire avec {demon_name}
[ALMA_ORDONNANCEMENT] â€” {demon_name}, recherche dans la mÃ©moire

[OUBLI_MEMORY] â€” Recherche conversationnelle et patterns
[OUBLI_INSIGHT] â€” Insights basÃ©s sur l'historique

[ALMA_DECISION] â€” DÃ©cision finale basÃ©e sur la mÃ©moire
"""
        
        elif relevant_demon == DaemonRole.MERGE:
            prompt += f"""
[ALMA_PLAN] â€” Plan d'action Git avec {demon_name}
[ALMA_ORDONNANCEMENT] â€” {demon_name}, prÃ©pare la gestion Git

[MERGE_GIT] â€” Actions Git anarchistes et branches
[MERGE_BRANCH] â€” Ã‰tat des branches et prÃ©paration fusion

[ALMA_DECISION] â€” DÃ©cision finale sur la stratÃ©gie Git
"""
        
        elif relevant_demon == DaemonRole.LILIETH:
            prompt += f"""
[ALMA_PLAN] â€” Plan d'action communication avec {demon_name}
[ALMA_ORDONNANCEMENT] â€” {demon_name}, gÃ¨re la communication utilisateur

[LILI_INTERFACE] â€” *voix caressante* Communication avec l'utilisateur
[LILI_USER] â€” Feedback et rÃ©actions utilisateur

[ALMA_DECISION] â€” DÃ©cision finale sur l'approche communication
"""
        
        elif relevant_demon == DaemonRole.ASSISTANT_V9:
            prompt += f"""
[ALMA_PLAN] â€” Plan d'action exÃ©cution avec {demon_name}
[ALMA_ORDONNANCEMENT] â€” {demon_name}, orchestre l'exÃ©cution

[V9_ORCHESTRATION] â€” Orchestration et planification d'exÃ©cution
[V9_EXECUTION] â€” ExÃ©cution somatique des actions

[ALMA_DECISION] â€” DÃ©cision finale sur l'exÃ©cution
"""
        
        return prompt
    
    def _get_daemon_prompt(self, user_input: str) -> str:
        """GÃ©nÃ¨re le prompt mutant pour l'Ã©quipe dÃ©moniaque"""
        
        # DÃ©tection du dÃ©mon pertinent
        relevant_demon = self._detect_relevant_demon(user_input)
        
        # GÃ©nÃ©ration du prompt mutant
        if self.silent_mode:
            # Mode silencieux : dialogue Almaâ›§ â†” Utilisateur
            return self._get_alma_user_dialogue_prompt(user_input)
        else:
            # Mode normal : dialogue Almaâ›§ â†” DÃ©mon pertinent
            return self._get_mutant_dialogue_prompt(user_input, relevant_demon)
    
    def _get_alma_user_dialogue_prompt(self, user_input: str) -> str:
        """GÃ©nÃ¨re un prompt pour dialogue Almaâ›§ â†” Utilisateur (mode silencieux)"""
        
        context_summary = ""
        if self.auto_feed_thread:
            try:
                context_summary = self.auto_feed_thread.get_context_summary(2)
            except:
                pass
        
        prompt = f"""â›§ DIALOGUE SILENCIEUX : ALMAâ›§ â†” UTILISATEUR â›§

CONTEXTE :
- Almaâ›§ (SUPREME) : Architecte DÃ©moniaque, planificateur stratÃ©gique
- Mode silencieux : Seule Almaâ›§ parle, fait des rÃ©sumÃ©s d'Ã©quipe

CONTEXTE RÃ‰CENT :
{context_summary}

DEMANDE UTILISATEUR : {user_input}

RÃ‰PONSE D'ALMAâ›§ (rÃ©sumÃ© d'Ã©quipe) :
[ALMA_PLAN] â€” Plan d'action stratÃ©gique dÃ©taillÃ©
[ALMA_DECISION] â€” DÃ©cision finale basÃ©e sur consultation Ã©quipe
[ALMA_SUMMARY] â€” RÃ©sumÃ© des insights de l'Ã©quipe dÃ©moniaque
"""
        
        return prompt
    
    async def process_user_input(self, user_input: str) -> str:
        """Traite une demande utilisateur avec l'Ã©quipe dÃ©moniaque"""
        print(f"ğŸ•·ï¸ Traitement de la demande : {user_input[:50]}...")
        
        # CrÃ©ation d'une nouvelle conversation
        import time
        self.conversation_counter += 1
        self.current_conversation = DaemonConversation(
            messages=[],
            user_input=user_input,
            timestamp=time.time(),
            conversation_id=f"conv_{self.conversation_counter}"
        )
        
        # GÃ©nÃ©ration du prompt
        prompt = self._get_daemon_prompt(user_input)
        
        # Appel LLM
        try:
            if self.provider:
                response = await self.provider.generate_response(prompt)
                daemon_response = response.content if hasattr(response, 'content') else str(response)
            else:
                # Mode mock pour test
                daemon_response = self._generate_mock_response(user_input)
        except Exception as e:
            print(f"âŒ Erreur LLM: {e}")
            daemon_response = self._generate_mock_response(user_input)
        
        # Parsing de la rÃ©ponse
        messages = self._parse_daemon_response(daemon_response)
        
        # Ajout des messages Ã  la conversation
        for msg in messages:
            self.current_conversation.add_message(msg)
        
        # Sauvegarde dans la couche mÃ©ta virtuelle
        if self.meta_virtual_layer:
            self.meta_virtual_layer.add_conversation(self.current_conversation)
        
        # Ajout dans l'auto feed thread
        if self.auto_feed_thread:
            try:
                self.auto_feed_thread.add_user_message(user_input)
                self.auto_feed_thread.add_self_message(daemon_response)
            except Exception as e:
                print(f"âš ï¸ Erreur auto feed thread: {e}")
        
        # Formatage de la rÃ©ponse finale
        if self.silent_mode:
            # Mode silencieux : seulement Almaâ›§
            alma_messages = [msg for msg in messages if msg.role == DaemonRole.ALMA]
            return "\n".join([msg.to_parsable_format() for msg in alma_messages])
        else:
            # Mode complet : tous les dÃ©mons
            return "\n".join([msg.to_parsable_format() for msg in messages])
    
    def _parse_daemon_response(self, response: str) -> List[DaemonMessage]:
        """Parse la rÃ©ponse LLM en messages de dÃ©mons"""
        messages = []
        
        # Pattern pour dÃ©tecter les messages parsables
        pattern = r'\[([A-Z_]+)\]\s*â€”\s*(.+)'
        matches = re.findall(pattern, response, re.MULTILINE)
        
        for message_type, content in matches:
            # DÃ©termination du rÃ´le selon le type de message
            role = self._get_role_from_message_type(message_type)
            if role:
                message = self._create_daemon_message(role, message_type, content.strip())
                messages.append(message)
        
        return messages
    
    def _get_role_from_message_type(self, message_type: str) -> Optional[DaemonRole]:
        """DÃ©termine le rÃ´le du dÃ©mon selon le type de message"""
        type_to_role = {
            # Almaâ›§
            "ALMA_PLAN": DaemonRole.ALMA,
            "ALMA_DECISION": DaemonRole.ALMA,
            "ALMA_ORDONNANCEMENT": DaemonRole.ALMA,
            "ALMA_SUMMARY": DaemonRole.ALMA,
            
            # Bask'tur
            "BASK_ANALYSIS": DaemonRole.BASKTUR,
            "BASK_SOLUTION": DaemonRole.BASKTUR,
            "BASK_DEBUG": DaemonRole.BASKTUR,
            
            # Oubliade
            "OUBLI_MEMORY": DaemonRole.OUBLIADE,
            "OUBLI_INSIGHT": DaemonRole.OUBLIADE,
            "OUBLI_SEARCH": DaemonRole.OUBLIADE,
            
            # Merge
            "MERGE_GIT": DaemonRole.MERGE,
            "MERGE_BRANCH": DaemonRole.MERGE,
            "MERGE_CONFLICT": DaemonRole.MERGE,
            
            # Lil.ieth
            "LILI_INTERFACE": DaemonRole.LILIETH,
            "LILI_USER": DaemonRole.LILIETH,
            "LILI_FEEDBACK": DaemonRole.LILIETH,
            
            # Assistant V9
            "V9_ORCHESTRATION": DaemonRole.ASSISTANT_V9,
            "V9_EXECUTION": DaemonRole.ASSISTANT_V9,
            "V9_SOMATIC": DaemonRole.ASSISTANT_V9,
        }
        
        return type_to_role.get(message_type)
    
    def _generate_mock_response(self, user_input: str) -> str:
        """GÃ©nÃ¨re une rÃ©ponse mock pour les tests"""
        return f"""[ALMA_PLAN] â€” Plan d'action : Analyser la demande "{user_input}" et proposer une solution stratÃ©gique
[ALMA_ORDONNANCEMENT] â€” Bask'tur : Analyse technique. Oubliade : Recherche mÃ©moire. Merge : PrÃ©parer branche.

[BASK_ANALYSIS] â€” Demande utilisateur dÃ©tectÃ©e : {user_input}
[BASK_SOLUTION] â€” Solution technique recommandÃ©e : ImplÃ©mentation daemonique

[OUBLI_MEMORY] â€” Recherche conversationnelle : Patterns similaires trouvÃ©s
[OUBLI_INSIGHT] â€” Utilisateur prÃ©fÃ¨re les solutions robustes

[MERGE_GIT] â€” Branche "DaemonSolution_v1" crÃ©Ã©e
[MERGE_BRANCH] â€” PrÃªt pour fusion aprÃ¨s validation

[LILI_INTERFACE] â€” *"Ton projet va Ãªtre magnifique, mon amour !"*
[LILI_USER] â€” Feedback utilisateur : "{user_input}"

[ALMA_DECISION] â€” DÃ©cision finale : ImplÃ©menter solution daemonique
[V9_ORCHESTRATION] â€” ExÃ©cution selon plan dÃ©taillÃ©"""

    def get_conversation_stats(self) -> Dict[str, Any]:
        """Retourne les statistiques de conversation"""
        if not self.meta_virtual_layer:
            return {"error": "Meta virtual layer non disponible"}
        
        patterns = self.meta_virtual_layer.analyze_daemon_interaction_patterns()
        
        stats = {
            "total_conversations": len(self.meta_virtual_layer.conversation_history),
            "silent_mode": self.silent_mode,
            "patterns": patterns
        }
        
        if self.auto_feed_thread:
            try:
                thread_stats = self.auto_feed_thread.get_thread_stats()
                stats["auto_feed_thread"] = thread_stats
            except:
                pass
        
        return stats
    
    def search_conversations(self, query: str) -> List[DaemonConversation]:
        """Recherche dans les conversations"""
        if not self.meta_virtual_layer:
            return []
        
        return self.meta_virtual_layer.search_daemon_conversations(query)
    
    def toggle_silent_mode(self):
        """Bascule le mode silencieux"""
        self.silent_mode = not self.silent_mode
        print(f"ğŸ”‡ Mode silencieux : {'activÃ©' if self.silent_mode else 'dÃ©sactivÃ©'}")


# Fonction de test
async def test_legion_auto_feeding_thread():
    """Test de LegionAutoFeedingThread"""
    print("ğŸ•·ï¸ Test de LegionAutoFeedingThread...")
    
    # CrÃ©ation de l'instance
    legion = LegionAutoFeedingThread(
        workspace_path=".",
        silent_mode=False,
        max_history=20,
        enable_cache=True
    )
    
    # Test 1 : Mode normal
    print("\nğŸ“ Test 1 : Mode normal")
    response1 = await legion.process_user_input("Analyse ce projet et propose des amÃ©liorations")
    print("RÃ©ponse :")
    print(response1)
    
    # Test 2 : Mode silencieux
    print("\nğŸ”‡ Test 2 : Mode silencieux")
    legion.toggle_silent_mode()
    response2 = await legion.process_user_input("CrÃ©e un nouveau fichier de test")
    print("RÃ©ponse :")
    print(response2)
    
    # Test 3 : Statistiques
    print("\nğŸ“Š Test 3 : Statistiques")
    stats = legion.get_conversation_stats()
    print("Stats :")
    print(json.dumps(stats, indent=2, ensure_ascii=False))
    
    # Test 4 : Recherche
    print("\nğŸ” Test 4 : Recherche")
    results = legion.search_conversations("amÃ©liorations")
    print(f"RÃ©sultats de recherche : {len(results)} conversations trouvÃ©es")
    
    print("\nâœ… Test LegionAutoFeedingThread terminÃ© !")


if __name__ == "__main__":
    asyncio.run(test_legion_auto_feeding_thread()) 