"""
‚õß Temporal User Request Memory - M√©moire Temporelle des Requ√™tes Utilisateur ‚õß

M√©moire temporelle des requ√™tes utilisateur refactoris√©e avec dimension temporelle universelle,
auto-am√©lioration et int√©gration native dans l'architecture temporelle.

Architecte D√©moniaque : Alma‚õß
Visionnaire : Lucie Defraiteur - Ma Reine Lucie
"""

import json
import asyncio
import threading
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
from queue import Queue, Empty

from .temporal_base import (
    BaseTemporalEntity,
    register_temporal_entity,
    unregister_temporal_entity
)
from .temporal_memory_node import TemporalMemoryNode

class TemporalUserRequestMemory(BaseTemporalEntity):
    """
    ‚õß M√©moire Temporelle des Requ√™tes Utilisateur - Architecture Temporelle ‚õß
    
    M√©moire temporelle des requ√™tes utilisateur avec dimension temporelle universelle,
    auto-am√©lioration et int√©gration native dans l'architecture temporelle.
    """
    
    def __init__(self, 
                 base_path: str, 
                 memory_engine=None,
                 polling_interval: float = 1.0,
                 auto_adapt: bool = True):
        """
        Initialise la m√©moire temporelle des requ√™tes utilisateur.
        
        Args:
            base_path: Chemin de base pour le stockage
            memory_engine: Instance du moteur temporel
            polling_interval: Intervalle de polling pour l'orchestrateur
            auto_adapt: Active l'adaptation automatique
        """
        # Initialisation de la base temporelle
        super().__init__(
            entity_id=f"temporal_user_request_memory_{datetime.now().isoformat()}",
            entity_type="temporal_user_request_memory"
        )
        
        # Configuration du stockage
        self.base_path = Path(base_path)
        self.temporal_dir = self.base_path / "memory" / "temporal_user_requests"
        self.temporal_dir.mkdir(parents=True, exist_ok=True)
        
        # R√©f√©rence au moteur temporel
        self.memory_engine = memory_engine
        
        # Configuration de l'adaptation
        self.auto_adapt = auto_adapt
        
        # Stack temporel des requ√™tes
        self.temporal_pending_requests = []  # Requ√™tes en attente temporelles
        self.temporal_processed_requests = []  # Requ√™tes trait√©es temporelles
        
        # Thread parall√®le pour l'Orchestrateur temporel
        self.orchestrator_thread = None
        self.orchestrator_running = False
        self.polling_interval = polling_interval
        
        # Communication thread-safe temporelle
        self.request_queue = Queue()
        self.orchestrator_queue = Queue()
        self.lock = threading.Lock()
        
        # Index temporel unifi√©
        self.temporal_index = {
            "pending": [],
            "processed": [],
            "by_intention": {},
            "by_priority": {"critical": [], "high": [], "normal": [], "low": []},
            "by_consciousness_level": {}
        }
        
        # Chargement des donn√©es temporelles existantes
        self._load_temporal_data()
        
        # D√©marrage du thread Orchestrateur temporel
        self._start_temporal_orchestrator_thread()
        
        # Enregistrement dans l'index temporel global
        register_temporal_entity(self)
        
        # √âvolution initiale
        self.temporal_dimension.evolve("Initialisation de la m√©moire temporelle des requ√™tes utilisateur")
    
    def _load_temporal_data(self):
        """Charge les donn√©es temporelles existantes."""
        pending_file = self.temporal_dir / "temporal_pending_requests.json"
        processed_file = self.temporal_dir / "temporal_processed_requests.json"
        
        if pending_file.exists():
            try:
                with open(pending_file, 'r', encoding='utf-8') as f:
                    self.temporal_pending_requests = json.load(f)
            except Exception as e:
                print(f"‚õß Erreur lors du chargement des requ√™tes en attente: {e}")
        
        if processed_file.exists():
            try:
                with open(processed_file, 'r', encoding='utf-8') as f:
                    self.temporal_processed_requests = json.load(f)
            except Exception as e:
                print(f"‚õß Erreur lors du chargement des requ√™tes trait√©es: {e}")
        
        # Migration vers le format temporel si n√©cessaire
        self._migrate_to_temporal_format()
    
    def _migrate_to_temporal_format(self):
        """Migre les donn√©es vers le format temporel."""
        # Migration des requ√™tes en attente
        for request in self.temporal_pending_requests:
            if "temporal_dimension" not in request:
                request["temporal_dimension"] = {
                    "created_at": request.get("timestamp", datetime.now().isoformat()),
                    "modified_at": request.get("timestamp", datetime.now().isoformat()),
                    "version": "1.0",
                    "evolution_history": ["Migration vers format temporel"],
                    "consciousness_level": "AWARE"
                }
        
        # Migration des requ√™tes trait√©es
        for request in self.temporal_processed_requests:
            if "temporal_dimension" not in request:
                request["temporal_dimension"] = {
                    "created_at": request.get("timestamp", datetime.now().isoformat()),
                    "modified_at": request.get("timestamp", datetime.now().isoformat()),
                    "version": "1.0",
                    "evolution_history": ["Migration vers format temporel"],
                    "consciousness_level": "AWARE"
                }
    
    def _save_temporal_data(self):
        """Sauvegarde les donn√©es temporelles."""
        pending_file = self.temporal_dir / "temporal_pending_requests.json"
        processed_file = self.temporal_dir / "temporal_processed_requests.json"
        
        try:
            with open(pending_file, 'w', encoding='utf-8') as f:
                json.dump(self.temporal_pending_requests, f, indent=2, ensure_ascii=False)
            
            with open(processed_file, 'w', encoding='utf-8') as f:
                json.dump(self.temporal_processed_requests, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"‚õß Erreur lors de la sauvegarde des donn√©es temporelles: {e}")
    
    def _start_temporal_orchestrator_thread(self):
        """D√©marre le thread parall√®le de l'Orchestrateur temporel."""
        self.orchestrator_running = True
        self.orchestrator_thread = threading.Thread(
            target=self._temporal_orchestrator_loop,
            daemon=True,
            name="TemporalOrchestratorThread"
        )
        self.orchestrator_thread.start()
        print(f"üöÄ Thread Orchestrateur Temporel d√©marr√© (polling: {self.polling_interval}s)")
    
    def _temporal_orchestrator_loop(self):
        """Boucle principale du thread Orchestrateur temporel."""
        while self.orchestrator_running:
            try:
                # Polling des requ√™tes en attente temporelles
                with self.lock:
                    if self.temporal_pending_requests:
                        batch = self._prepare_temporal_batch_for_orchestrator()
                        if batch:
                            self._send_to_temporal_orchestrator(batch)
                            self._mark_temporal_requests_as_processed(batch["requests"])
                
                # Traitement des messages de l'Orchestrateur temporel
                try:
                    while True:
                        message = self.orchestrator_queue.get_nowait()
                        self._handle_temporal_orchestrator_message(message)
                except Empty:
                    pass
                
                time.sleep(self.polling_interval)
                
            except Exception as e:
                print(f"‚õß Erreur dans la boucle Orchestrateur Temporel: {e}")
                time.sleep(self.polling_interval)
    
    def _prepare_temporal_batch_for_orchestrator(self) -> Optional[Dict[str, Any]]:
        """Pr√©pare un batch temporel pour l'Orchestrateur."""
        if not self.temporal_pending_requests:
            return None
        
        # S√©lection des requ√™tes prioritaires
        critical_requests = [r for r in self.temporal_pending_requests if r.get("priority") == "critical"]
        high_requests = [r for r in self.temporal_pending_requests if r.get("priority") == "high"]
        normal_requests = [r for r in self.temporal_pending_requests if r.get("priority") == "normal"]
        
        # Construction du batch temporel
        batch_requests = critical_requests[:5] + high_requests[:10] + normal_requests[:20]
        
        if not batch_requests:
            return None
        
        batch = {
            "batch_id": f"temporal_batch_{datetime.now().isoformat()}",
            "timestamp": datetime.now().isoformat(),
            "requests": batch_requests,
            "temporal_dimension": {
                "created_at": datetime.now().isoformat(),
                "modified_at": datetime.now().isoformat(),
                "version": "1.0",
                "evolution_history": ["Cr√©ation du batch temporel"],
                "consciousness_level": "AWARE"
            }
        }
        
        return batch
    
    def _mark_temporal_requests_as_processed(self, requests: List[Dict[str, Any]]):
        """Marque les requ√™tes temporelles comme trait√©es."""
        request_ids = [r["id"] for r in requests]
        
        # D√©placement des requ√™tes vers trait√©es
        with self.lock:
            self.temporal_pending_requests = [
                r for r in self.temporal_pending_requests 
                if r["id"] not in request_ids
            ]
            
            for request in requests:
                request["processed_at"] = datetime.now().isoformat()
                request["temporal_dimension"]["modified_at"] = datetime.now().isoformat()
                request["temporal_dimension"]["evolution_history"].append("Marqu√©e comme trait√©e")
                self.temporal_processed_requests.append(request)
        
        # Sauvegarde temporelle
        self._save_temporal_data()
    
    def _send_to_temporal_orchestrator(self, batch_message: Dict[str, Any]):
        """Envoie un batch temporel √† l'Orchestrateur."""
        try:
            # Simulation d'envoi √† l'Orchestrateur temporel
            print(f"‚õß Envoi du batch temporel {batch_message['batch_id']} √† l'Orchestrateur")
            
            # Cr√©ation d'un n≈ìud de m√©moire temporel pour le batch
            if self.memory_engine:
                asyncio.create_task(self._create_batch_memory_node(batch_message))
            
        except Exception as e:
            print(f"‚õß Erreur lors de l'envoi du batch temporel: {e}")
    
    async def _create_batch_memory_node(self, batch_message: Dict[str, Any]):
        """Cr√©e un n≈ìud de m√©moire temporel pour le batch."""
        try:
            batch_content = f"Batch de {len(batch_message['requests'])} requ√™tes"
            batch_metadata = {
                "batch_id": batch_message["batch_id"],
                "requests_count": len(batch_message["requests"]),
                "priorities": {
                    "critical": len([r for r in batch_message["requests"] if r.get("priority") == "critical"]),
                    "high": len([r for r in batch_message["requests"] if r.get("priority") == "high"]),
                    "normal": len([r for r in batch_message["requests"] if r.get("priority") == "normal"])
                }
            }
            
            await self.memory_engine.create_temporal_memory(
                node_type="user_request_batch",
                content=batch_content,
                metadata=batch_metadata,
                keywords=["batch", "orchestrator", "user_requests"],
                strata="cognitive"
            )
        except Exception as e:
            print(f"‚õß Erreur lors de la cr√©ation du n≈ìud de m√©moire batch: {e}")
    
    def _handle_temporal_orchestrator_message(self, message: Dict[str, Any]):
        """G√®re les messages de l'Orchestrateur temporel."""
        try:
            message_type = message.get("type", "unknown")
            
            if message_type == "batch_processed":
                print(f"‚õß Batch temporel trait√©: {message.get('batch_id')}")
            elif message_type == "error":
                print(f"‚õß Erreur Orchestrateur Temporel: {message.get('error')}")
            else:
                print(f"‚õß Message Orchestrateur Temporel: {message}")
            
            # Apprentissage de l'interaction
            self.learn_from_interaction("orchestrator_message", {
                "message_type": message_type,
                "message": message
            })
            
        except Exception as e:
            print(f"‚õß Erreur lors du traitement du message Orchestrateur Temporel: {e}")
    
    async def add_temporal_user_request(self, 
                                      request_text: str, 
                                      request_type: str = "terminal", 
                                      metadata: Dict = None) -> str:
        """
        Ajoute une requ√™te utilisateur temporelle.
        
        Args:
            request_text: Texte de la requ√™te
            request_type: Type de requ√™te (terminal, web, api, etc.)
            metadata: M√©tadonn√©es suppl√©mentaires
        
        Returns:
            str: ID de la requ√™te cr√©√©e
        """
        request_id = f"temporal_request_{datetime.now().isoformat()}"
        
        # Analyse temporelle de l'intention
        intention_analysis = await self._analyze_temporal_intention(request_text)
        
        # Calcul temporel de la priorit√©
        priority = await self._calculate_temporal_priority(request_text, intention_analysis)
        
        # Cr√©ation de l'entr√©e de requ√™te temporelle
        request_entry = {
            "id": request_id,
            "timestamp": datetime.now().isoformat(),
            "request_text": request_text,
            "request_type": request_type,
            "intention": intention_analysis,
            "priority": priority,
            "metadata": metadata or {},
            "status": "pending",
            "temporal_dimension": {
                "created_at": datetime.now().isoformat(),
                "modified_at": datetime.now().isoformat(),
                "version": "1.0",
                "evolution_history": ["Cr√©ation de la requ√™te temporelle"],
                "consciousness_level": "AWARE"
            }
        }
        
        # Ajout √† la liste des requ√™tes en attente
        with self.lock:
            self.temporal_pending_requests.append(request_entry)
        
        # Indexation temporelle
        await self._index_temporal_request(request_entry)
        
        # Cr√©ation d'un n≈ìud de m√©moire temporel pour la requ√™te
        if self.memory_engine:
            await self._create_request_memory_node(request_entry)
        
        # Sauvegarde temporelle
        self._save_temporal_data()
        
        # √âvolution de la m√©moire
        self.temporal_dimension.evolve(f"Ajout de requ√™te utilisateur: {request_type}")
        
        # Apprentissage de l'interaction
        self.learn_from_interaction("user_request_added", {
            "request_type": request_type,
            "priority": priority,
            "intention": intention_analysis.get("primary_intention", "unknown")
        })
        
        print(f"‚õß Requ√™te utilisateur temporelle ajout√©e: {request_id}")
        return request_id
    
    async def _analyze_temporal_intention(self, request_text: str) -> Dict[str, Any]:
        """Analyse temporelle de l'intention de la requ√™te."""
        # Analyse simple pour l'instant
        # TODO: Int√©grer le syst√®me d'enrichissement et l'IA
        
        intentions = {
            "search": ["cherche", "trouve", "recherche", "search", "find"],
            "create": ["cr√©e", "cr√©er", "nouveau", "new", "create"],
            "modify": ["modifie", "change", "update", "modifier"],
            "delete": ["supprime", "delete", "remove", "efface"],
            "analyze": ["analyse", "analyze", "examine", "√©tudie"],
            "debug": ["debug", "corrige", "fix", "r√©pare"]
        }
        
        request_lower = request_text.lower()
        detected_intentions = []
        
        for intention, keywords in intentions.items():
            if any(keyword in request_lower for keyword in keywords):
                detected_intentions.append(intention)
        
        primary_intention = detected_intentions[0] if detected_intentions else "unknown"
        
        return {
            "primary_intention": primary_intention,
            "detected_intentions": detected_intentions,
            "confidence": len(detected_intentions) / len(intentions) if detected_intentions else 0.0
        }
    
    async def _calculate_temporal_priority(self, request_text: str, intention_analysis: Dict[str, Any]) -> str:
        """Calcule la priorit√© temporelle de la requ√™te."""
        # Logique de priorit√© temporelle
        # TODO: Am√©liorer avec l'IA et l'historique temporel
        
        primary_intention = intention_analysis.get("primary_intention", "unknown")
        confidence = intention_analysis.get("confidence", 0.0)
        
        # Priorit√©s par intention
        critical_intentions = ["debug", "delete"]
        high_intentions = ["create", "modify"]
        normal_intentions = ["search", "analyze"]
        
        if primary_intention in critical_intentions:
            return "critical"
        elif primary_intention in high_intentions:
            return "high"
        elif primary_intention in normal_intentions:
            return "normal"
        else:
            return "low"
    
    async def _index_temporal_request(self, request_entry: Dict[str, Any]):
        """Indexe la requ√™te temporelle."""
        # Indexation par intention
        primary_intention = request_entry["intention"]["primary_intention"]
        if primary_intention not in self.temporal_index["by_intention"]:
            self.temporal_index["by_intention"][primary_intention] = []
        self.temporal_index["by_intention"][primary_intention].append(request_entry["id"])
        
        # Indexation par priorit√©
        priority = request_entry["priority"]
        self.temporal_index["by_priority"][priority].append(request_entry["id"])
        
        # Indexation par niveau de conscience
        consciousness_level = request_entry["temporal_dimension"]["consciousness_level"]
        if consciousness_level not in self.temporal_index["by_consciousness_level"]:
            self.temporal_index["by_consciousness_level"][consciousness_level] = []
        self.temporal_index["by_consciousness_level"][consciousness_level].append(request_entry["id"])
    
    async def _create_request_memory_node(self, request_entry: Dict[str, Any]):
        """Cr√©e un n≈ìud de m√©moire temporel pour la requ√™te."""
        try:
            request_metadata = {
                "request_id": request_entry["id"],
                "request_type": request_entry["request_type"],
                "priority": request_entry["priority"],
                "intention": request_entry["intention"],
                "status": request_entry["status"],
                **(request_entry.get("metadata", {}))
            }
            
            await self.memory_engine.create_temporal_memory(
                node_type="user_request",
                content=request_entry["request_text"],
                metadata=request_metadata,
                keywords=[
                    request_entry["request_type"],
                    request_entry["priority"],
                    request_entry["intention"]["primary_intention"]
                ],
                strata="somatic"
            )
        except Exception as e:
            print(f"‚õß Erreur lors de la cr√©ation du n≈ìud de m√©moire requ√™te: {e}")
    
    async def get_temporal_statistics(self) -> Dict[str, Any]:
        """R√©cup√®re les statistiques temporelles."""
        stats = {
            "total_pending": len(self.temporal_pending_requests),
            "total_processed": len(self.temporal_processed_requests),
            "by_priority": {
                priority: len([r for r in self.temporal_pending_requests if r.get("priority") == priority])
                for priority in ["critical", "high", "normal", "low"]
            },
            "by_intention": {
                intention: len(ids) for intention, ids in self.temporal_index["by_intention"].items()
            },
            "temporal_dimension": self.temporal_dimension.to_dict(),
            "consciousness_level": self.consciousness_interface.consciousness_level.value
        }
        
        return stats
    
    async def search_temporal_requests(self, 
                                    query_type: str, 
                                    query_value: str) -> List[Dict[str, Any]]:
        """Recherche temporelle dans les requ√™tes."""
        results = []
        
        if query_type == "intention":
            request_ids = self.temporal_index["by_intention"].get(query_value, [])
            all_requests = self.temporal_pending_requests + self.temporal_processed_requests
            results = [r for r in all_requests if r["id"] in request_ids]
        
        elif query_type == "priority":
            request_ids = self.temporal_index["by_priority"].get(query_value, [])
            all_requests = self.temporal_pending_requests + self.temporal_processed_requests
            results = [r for r in all_requests if r["id"] in request_ids]
        
        elif query_type == "text":
            all_requests = self.temporal_pending_requests + self.temporal_processed_requests
            results = [
                r for r in all_requests 
                if query_value.lower() in r["request_text"].lower()
            ]
        
        # Apprentissage de l'interaction
        self.learn_from_interaction("request_search", {
            "query_type": query_type,
            "query_value": query_value,
            "results_count": len(results)
        })
        
        return results
    
    def stop_temporal_orchestrator_thread(self):
        """Arr√™te le thread Orchestrateur temporel."""
        self.orchestrator_running = False
        if self.orchestrator_thread:
            self.orchestrator_thread.join(timeout=5.0)
        print("‚õß Thread Orchestrateur Temporel arr√™t√©")
    
    async def auto_improve_content(self) -> bool:
        """Auto-am√©lioration du contenu de la m√©moire temporelle."""
        improved = await super().auto_improve_content()
        
        # Auto-am√©lioration des requ√™tes temporelles
        for request in self.temporal_pending_requests + self.temporal_processed_requests:
            if "temporal_dimension" in request:
                # √âvolution temporelle des requ√™tes
                request["temporal_dimension"]["modified_at"] = datetime.now().isoformat()
                request["temporal_dimension"]["evolution_history"].append("Auto-am√©lioration")
        
        return improved
    
    def get_entity_specific_data(self) -> Dict[str, Any]:
        """Retourne les donn√©es sp√©cifiques de la m√©moire temporelle."""
        return {
            "base_path": str(self.base_path),
            "temporal_dir": str(self.temporal_dir),
            "pending_requests_count": len(self.temporal_pending_requests),
            "processed_requests_count": len(self.temporal_processed_requests),
            "orchestrator_running": self.orchestrator_running,
            "polling_interval": self.polling_interval,
            "memory_engine_connected": self.memory_engine is not None
        }
    
    def get_statistics(self) -> Dict[str, Any]:
        """Retourne les statistiques de la m√©moire temporelle."""
        stats = {
            "memory_type": "TemporalUserRequestMemory",
            "temporal_dimension": self.temporal_dimension.to_dict(),
            "consciousness_level": self.consciousness_interface.consciousness_level.value,
            "pending_requests_count": len(self.temporal_pending_requests),
            "processed_requests_count": len(self.temporal_processed_requests),
            "orchestrator_running": self.orchestrator_running
        }
        
        # Statistiques par priorit√©
        priority_stats = {}
        for priority in ["critical", "high", "normal", "low"]:
            priority_stats[priority] = len([
                r for r in self.temporal_pending_requests 
                if r.get("priority") == priority
            ])
        
        stats["priority_stats"] = priority_stats
        
        return stats
    
    def __del__(self):
        """Destructeur pour arr√™ter le thread Orchestrateur temporel."""
        self.stop_temporal_orchestrator_thread() 