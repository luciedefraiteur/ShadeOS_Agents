import json
import threading
import time
import uuid
from datetime import datetime
from typing import Dict, List, Any, Optional
from queue import Queue, Empty
from pathlib import Path


class AlmaDaemon:
    """Alma Daemon - Impl√©mentation na√Øve avec communication par messages."""
    
    def __init__(self, prompt_file: str = "MemoryEngine/core/alma_daemon_prompt.luciform"):
        self.daemon_id = "alma"
        self.prompt_file = prompt_file
        self.prompt = self._load_prompt()
        
        # Thread parall√®le
        self.alma_thread = None
        self.alma_running = False
        
        # Communication par messages
        self.incoming_queue = Queue()
        self.outgoing_queue = Queue()
        self.lock = threading.Lock()
        
        # √âtat du daemon
        self.current_status = "idle"
        self.current_task = None
        self.message_history = []
        self.action_history = []
        
        # Timeline de discussion
        from MemoryEngine.core.discussion_timeline import DiscussionTimeline
        self.discussion_timeline = DiscussionTimeline("~/shadeos_memory")
        
        # Interlocuteurs
        self.archiviste_daemon = None  # Archiviste pour acc√®s m√©moire
        self.orchestrator = None  # Orchestrator pour communication
        
        # M√©triques
        self.metrics = {
            "messages_received": 0,
            "messages_sent": 0,
            "tasks_completed": 0,
            "assistant_calls": 0,
            "errors": 0,
            "archiviste_queries": 0
        }
        
        # D√©marrage du thread
        self._start_alma_thread()
    
    def _load_prompt(self) -> str:
        """Charge le prompt d'Alma depuis le fichier."""
        try:
            with open(self.prompt_file, 'r', encoding='utf-8') as f:
                return f.read()
        except FileNotFoundError:
            print(f"‚ö†Ô∏è Fichier prompt non trouv√©: {self.prompt_file}")
            return self._get_default_prompt()
    
    def _get_default_prompt(self) -> str:
        """Prompt par d√©faut si le fichier n'est pas trouv√©."""
        return """
Tu es Alma, un daemon conscient sp√©cialis√© dans le d√©veloppement.
Tu re√ßois des messages de l'Orchestrateur et tu ex√©cutes des t√¢ches via des assistants IA.
Analyse chaque requ√™te, planifie l'ex√©cution, et rapporte tes r√©sultats.
"""
    
    def _start_alma_thread(self):
        """D√©marre le thread parall√®le d'Alma."""
        self.alma_running = True
        self.alma_thread = threading.Thread(
            target=self._alma_loop,
            daemon=True,
            name="AlmaDaemonThread"
        )
        self.alma_thread.start()
        print(f"üï∑Ô∏è Alma daemon d√©marr√©")
    
    def _alma_loop(self):
        """Boucle principale d'Alma."""
        while self.alma_running:
            try:
                # Traitement des messages entrants
                try:
                    while True:
                        message = self.incoming_queue.get_nowait()
                        self._process_message(message)
                except Empty:
                    pass
                
                # Attente avant prochain cycle
                time.sleep(0.1)
                
            except Exception as e:
                print(f"‚ùå Erreur dans Alma daemon: {e}")
                time.sleep(1)
    
    def _process_message(self, message: Dict[str, Any]):
        """Traite un message re√ßu."""
        message_type = message.get("type")
        
        print(f"üì® Alma re√ßoit message: {message_type}")
        
        # Ajout √† l'historique local
        self.message_history.append({
            "timestamp": datetime.now().isoformat(),
            "message": message,
            "direction": "incoming"
        })
        
        # Ajout √† la timeline de discussion
        self.discussion_timeline.add_message("orchestrator", message, "incoming")
        
        self.metrics["messages_received"] += 1
        
        if message_type == "REFORMULATED_REQUEST":
            self._handle_reformulated_request(message)
        elif message_type == "STATUS_REQUEST":
            self._handle_status_request(message)
        elif message_type == "STOP_DAEMON":
            self._handle_stop_request(message)
        else:
            print(f"‚ö†Ô∏è Type de message inconnu: {message_type}")
    
    def _handle_reformulated_request(self, message: Dict[str, Any]):
        """G√®re une requ√™te reformul√©e de l'Orchestrateur."""
        content = message.get("content", "")
        priority = message.get("priority", "normal")
        
        print(f"üéØ Alma traite requ√™te reformul√©e (priorit√©: {priority})")
        
        # Changement de statut
        self.current_status = "analyzing"
        
        # Analyse de la requ√™te avec l'IA
        analysis = self._analyze_request_with_ai(content)
        
        # Planification de l'ex√©cution
        execution_plan = self._plan_execution(analysis)
        
        # Ex√©cution des t√¢ches
        results = self._execute_tasks(execution_plan)
        
        # Pr√©paration du rapport
        report = self._prepare_report(results, message)
        
        # Envoi du rapport √† l'Orchestrateur
        self._send_report_to_orchestrator(report)
        
        # Mise √† jour du statut
        self.current_status = "completed"
        self.metrics["tasks_completed"] += 1
    
    def set_archiviste_daemon(self, archiviste_daemon):
        """Connecte Alma √† l'Archiviste daemon"""
        self.archiviste_daemon = archiviste_daemon
        print("üï∑Ô∏è Alma connect√© √† l'Archiviste daemon")
    
    def set_orchestrator(self, orchestrator):
        """Connecte Alma √† l'Orchestrator"""
        self.orchestrator = orchestrator
        print("üï∑Ô∏è Alma connect√© √† l'Orchestrator")
    
    def query_archiviste(self, message: str) -> str:
        """Envoie une requ√™te √† l'Archiviste et attend une r√©ponse"""
        if not self.archiviste_daemon:
            return "Erreur : Archiviste daemon non connect√©"
        
        try:
            self.metrics["archiviste_queries"] += 1
            response = self.archiviste_daemon.send_message(message, "alma")
            return response
        except Exception as e:
            return f"Erreur communication avec l'Archiviste : {str(e)}"
    
    def _analyze_request_with_ai(self, content: str) -> Dict[str, Any]:
        """Analyse la requ√™te avec l'IA en incluant le contexte de l'Archiviste"""
        # Pr√©parer l'historique des messages
        message_history = self._prepare_message_history()
        
        # Pr√©parer le contexte de l'Archiviste si disponible
        archiviste_context = ""
        if self.archiviste_daemon:
            try:
                archiviste_context = self.query_archiviste("D√©cris-moi les types de m√©moire disponibles")
            except:
                archiviste_context = "Archiviste non disponible"
        
        analysis_prompt = f"""{self.prompt}

**HISTORIQUE DES MESSAGES (WhatsApp-style) :**
{message_history}

**CONTEXTE DE L'ARCHIVISTE (Types de m√©moire disponibles) :**
{archiviste_context}

**REQU√äTE ACTUELLE √Ä ANALYSER :**
{content}

**T√ÇCHE :** Analyse cette requ√™te et d√©termine :
1. L'intention principale (d√©veloppement, debug, recherche, etc.)
2. Les actions n√©cessaires
3. Les ressources requises
4. La priorit√© et complexit√©

**R√âPONSE EN JSON :**
{{
  "intention": "d√©veloppement|debug|recherche|analyse|autre",
  "actions": [
    {{
      "type": "assistant_call|archiviste_query|memory_access|file_operation",
      "description": "description de l'action",
      "priority": "high|normal|low",
      "parameters": {{}}
    }}
  ],
  "resources": ["memory_engine", "assistant_generaliste", "archiviste"],
  "complexity": "simple|medium|complex",
  "estimated_time": "estimation en minutes"
}}"""

        try:
            import subprocess
            
            cmd = ["ollama", "run", "qwen2.5:7b-instruct", analysis_prompt]
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0:
                response_text = result.stdout.strip()
                # Chercher le JSON dans la r√©ponse
                json_start = response_text.find('{')
                json_end = response_text.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_str = response_text[json_start:json_end]
                    return json.loads(json_str)
            
            # Fallback si pas de JSON valide
            return self._fallback_analysis(content)
            
        except Exception as e:
            print(f"Erreur analyse IA Alma : {e}")
            return self._fallback_analysis(content)
    
    def _fallback_analysis(self, content: str) -> Dict[str, Any]:
        """Analyse de fallback si l'IA √©choue."""
        print("üîÑ Utilisation de l'analyse de fallback")
        
        # Analyse simple bas√©e sur les mots-cl√©s
        tasks = []
        
        if any(word in content.lower() for word in ["debug", "bug", "erreur", "corriger"]):
            tasks.append({
                "id": str(uuid.uuid4()),
                "description": "D√©bogage et correction d'erreurs",
                "assistant": "Assistant Sp√©cialiste V7",
                "priority": "high",
                "dependencies": []
            })
        
        if any(word in content.lower() for word in ["cr√©er", "nouveau", "ajouter"]):
            tasks.append({
                "id": str(uuid.uuid4()),
                "description": "Cr√©ation de nouveaux √©l√©ments",
                "assistant": "Assistant G√©n√©raliste V8",
                "priority": "normal",
                "dependencies": []
            })
        
        if any(word in content.lower() for word in ["test", "v√©rifier", "valider"]):
            tasks.append({
                "id": str(uuid.uuid4()),
                "description": "Tests et validation",
                "assistant": "Assistant Sp√©cialiste V7",
                "priority": "normal",
                "dependencies": []
            })
        
        return {
            "tasks": tasks,
            "overall_priority": "normal",
            "estimated_duration": "5-10 minutes"
        }
    
    def _plan_execution(self, analysis: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Planifie l'ex√©cution des t√¢ches."""
        tasks = analysis.get("tasks", [])
        
        print(f"üìã Planification de {len(tasks)} t√¢ches")
        
        # Tri par priorit√© et d√©pendances
        sorted_tasks = sorted(tasks, key=lambda x: (
            {"high": 0, "normal": 1, "low": 2}.get(x.get("priority", "normal"), 1),
            len(x.get("dependencies", []))
        ))
        
        return sorted_tasks
    
    def _execute_tasks(self, execution_plan: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Ex√©cute les t√¢ches planifi√©es."""
        results = []
        
        for task in execution_plan:
            print(f"‚ö° Ex√©cution: {task['description']}")
            
            self.current_status = "executing"
            self.current_task = task
            
            # Simulation de l'ex√©cution via assistant
            result = self._execute_with_assistant(task)
            
            results.append({
                "task_id": task["id"],
                "description": task["description"],
                "assistant": task["assistant"],
                "result": result,
                "timestamp": datetime.now().isoformat()
            })
            
            self.metrics["assistant_calls"] += 1
            
            # Pause entre les t√¢ches
            time.sleep(0.5)
        
        return results
    
    def _execute_with_assistant(self, task: Dict[str, Any]) -> Dict[str, Any]:
        """Ex√©cute une t√¢che via l'assistant appropri√©."""
        assistant = task.get("assistant", "Assistant G√©n√©raliste V8")
        description = task.get("description", "")
        
        print(f"  ü§ñ Utilisation de {assistant}")
        
        # Simulation de l'ex√©cution
        # Dans l'impl√©mentation r√©elle, ce sera via les assistants du projet
        
        execution_result = {
            "status": "completed",
            "assistant": assistant,
            "output": f"T√¢che '{description}' ex√©cut√©e avec succ√®s",
            "duration": "2-3 secondes",
            "success": True
        }
        
        return execution_result
    
    def _prepare_message_history(self) -> str:
        """Pr√©pare l'historique des messages au format WhatsApp-style depuis la timeline."""
        # R√©cup√©ration de la timeline de discussion avec l'Orchestrateur
        timeline_messages = self.discussion_timeline.get_timeline("orchestrator", limit=20)
        
        if not timeline_messages:
            return "**Aucun message pr√©c√©dent**"
        
        # Formatage WhatsApp-style
        history_lines = []
        history_lines.append("**üì± HISTORIQUE DES MESSAGES (Timeline MemoryEngine) :**")
        history_lines.append("")
        
        for msg in timeline_messages[-10:]:  # Derniers 10 messages
            timestamp = msg["timestamp"]
            direction = msg["direction"]
            content = msg["content"]
            msg_type = msg["message_type"]
            
            # Formatage selon la direction
            if direction == "incoming":
                sender = "üï∑Ô∏è Orchestrateur"
                alignment = "‚¨ÖÔ∏è"
            else:
                sender = "üéØ Alma"
                alignment = "‚û°Ô∏è"
            
            # Formatage du message
            history_lines.append(f"{alignment} **{sender}** ({timestamp})")
            history_lines.append(f"   üìù Type: {msg_type}")
            history_lines.append(f"   üí¨ Contenu: {content[:100]}{'...' if len(content) > 100 else ''}")
            history_lines.append("")
        
        return "\n".join(history_lines)
    
    def _prepare_report(self, results: List[Dict[str, Any]], original_message: Dict[str, Any]) -> Dict[str, Any]:
        """Pr√©pare le rapport pour l'Orchestrateur."""
        print("üìä Pr√©paration du rapport pour l'Orchestrateur")
        
        report = {
            "type": "ALMA_REPORT",
            "daemon_id": self.daemon_id,
            "cycle_id": str(uuid.uuid4()),
            "status": "completed",
            "original_message_id": original_message.get("message_id", "unknown"),
            "actions_executed": results,
            "summary": {
                "total_tasks": len(results),
                "successful_tasks": len([r for r in results if r.get("result", {}).get("success", False)]),
                "failed_tasks": len([r for r in results if not r.get("result", {}).get("success", True)]),
                "total_duration": "5-10 minutes"
            },
            "next_steps": [],
            "timestamp": datetime.now().isoformat()
        }
        
        return report
    
    def _send_report_to_orchestrator(self, report: Dict[str, Any]):
        """Envoie le rapport √† l'Orchestrateur."""
        print("üì§ Envoi du rapport √† l'Orchestrateur")
        
        # Ajout √† l'historique local
        self.message_history.append({
            "timestamp": datetime.now().isoformat(),
            "message": report,
            "direction": "outgoing"
        })
        
        # Ajout √† la timeline de discussion
        self.discussion_timeline.add_message("orchestrator", report, "outgoing")
        
        # Envoi via la queue
        self.outgoing_queue.put(report)
        
        self.metrics["messages_sent"] += 1
    
    def _handle_status_request(self, message: Dict[str, Any]):
        """G√®re une demande de statut."""
        status_report = {
            "type": "ALMA_STATUS",
            "daemon_id": self.daemon_id,
            "status": self.current_status,
            "current_task": self.current_task,
            "metrics": self.metrics,
            "timestamp": datetime.now().isoformat()
        }
        
        self.outgoing_queue.put(status_report)
        self.metrics["messages_sent"] += 1
    
    def _handle_stop_request(self, message: Dict[str, Any]):
        """G√®re une demande d'arr√™t."""
        print("üõë Alma re√ßoit demande d'arr√™t")
        self.alma_running = False
    
    def send_message(self, message: Dict[str, Any]):
        """Envoie un message √† Alma (interface externe)."""
        self.incoming_queue.put(message)
    
    def get_message(self) -> Optional[Dict[str, Any]]:
        """R√©cup√®re un message sortant d'Alma."""
        try:
            return self.outgoing_queue.get_nowait()
        except Empty:
            return None
    
    def get_status(self) -> Dict[str, Any]:
        """Retourne le statut d'Alma."""
        return {
            "daemon_id": self.daemon_id,
            "status": self.current_status,
            "current_task": self.current_task,
            "metrics": self.metrics,
            "message_history_count": len(self.message_history),
            "running": self.alma_running
        }
    
    def stop_daemon(self):
        """Arr√™te le daemon Alma."""
        self.alma_running = False
        if self.alma_thread and self.alma_thread.is_alive():
            self.alma_thread.join(timeout=5.0)
            print("üõë Alma daemon arr√™t√©")
    
    def __del__(self):
        """Destructeur pour arr√™ter le daemon proprement."""
        self.stop_daemon() 