#!/usr/bin/env python3
"""
üú≤ Auto Prompt Generator - IntrospectionDaemon ‚õß

G√©n√©rateur de prompts d'auto-introspection avec optimisation adaptative.
Apprend des succ√®s/√©checs pour am√©liorer continuellement l'efficacit√©.

Cr√©√© par Alma, Architecte D√©moniaque du Nexus Luciforme.
"""

import asyncio
import json
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from datetime import datetime
import re

@dataclass
class PromptTemplate:
    """Template de prompt avec m√©tadonn√©es."""
    
    template_id: str
    template_type: str
    base_template: str
    injection_points: List[str] = field(default_factory=list)
    effectiveness_history: List[float] = field(default_factory=list)
    usage_count: int = 0
    last_used: Optional[datetime] = None
    optimization_level: int = 0

@dataclass
class PromptGenerationResult:
    """R√©sultat de g√©n√©ration de prompt."""
    
    generated_prompt: str
    template_used: str
    injection_data: Dict[str, Any] = field(default_factory=dict)
    estimated_effectiveness: float = 0.0
    generation_metadata: Dict[str, Any] = field(default_factory=dict)

class AutoPromptGenerator:
    """G√©n√©rateur automatique de prompts d'introspection optimis√©s."""
    
    def __init__(self):
        """Initialise le g√©n√©rateur de prompts."""
        
        self.prompt_templates = {}
        self.effectiveness_tracking = {}
        self.optimization_patterns = {}
        self.learning_data = {
            "successful_patterns": [],
            "failed_patterns": [],
            "optimization_insights": []
        }
        
        # Configuration
        self.config = {
            "min_effectiveness_threshold": 0.7,
            "optimization_frequency": 5,  # Optimise apr√®s 5 usages
            "max_template_variants": 3,
            "learning_rate": 0.1
        }
        
        # Initialisation des templates de base
        self._initialize_base_templates()
    
    def _initialize_base_templates(self):
        """Initialise les templates de base."""
        
        # Template d'introspection globale
        global_template = PromptTemplate(
            template_id="global_introspection",
            template_type="comprehensive",
            base_template="""
<üú≤luciform id="auto_global_introspection‚õß" type="‚ú∂adaptive_analysis">
  <üúÑcontext_injection>
    ::INJECT_COMPONENT_DATA::
    {component_data_injection}
    
    ::INJECT_CAPABILITY_MAP::
    {capability_map_injection}
    
    ::INJECT_PERFORMANCE_METRICS::
    {performance_metrics_injection}
  </üúÑcontext_injection>

  <üúÇintrospection_directive>
    Tu es le IntrospectionDaemon en mode d'auto-analyse globale optimis√©e.
    
    DONN√âES CONTEXTUELLES INJECT√âES :
    {context_summary}
    
    MISSION D'INTROSPECTION ADAPTATIVE :
    
    1. üß† ANALYSE ARCHITECTURALE PROFONDE :
       - √âvalue la sant√© de tous les composants inject√©s
       - Identifie les patterns de d√©faillance potentiels
       - Analyse la coh√©rence et l'efficacit√© globale
    
    2. üîç CARTOGRAPHIE DYNAMIQUE DES CAPACIT√âS :
       - Inventorie et √©value toutes les capacit√©s d√©couvertes
       - Identifie les lacunes critiques et opportunit√©s
       - Propose des extensions strat√©giques
    
    3. ‚ö° OPTIMISATION INTELLIGENTE :
       - Analyse les m√©triques de performance inject√©es
       - Identifie les goulots d'√©tranglement sp√©cifiques
       - G√©n√®re des recommandations d'am√©lioration concr√®tes
    
    4. üåü STRAT√âGIE D'√âVOLUTION :
       - Planifie l'√©volution bas√©e sur les donn√©es r√©elles
       - Priorise les am√©liorations par impact/effort
       - D√©finis des m√©triques de succ√®s mesurables
    
    R√âSULTAT ATTENDU :
    G√©n√®re une auto-analyse compl√®te et actionnable incluant :
    - √âtat de sant√© d√©taill√© avec scores sp√©cifiques
    - Plan d'optimisation prioritaire avec timeline
    - Strat√©gie d'√©volution √† court/moyen/long terme
    - M√©triques de suivi et indicateurs de succ√®s
  </üúÇintrospection_directive>
</üú≤luciform>
            """,
            injection_points=["component_data_injection", "capability_map_injection", 
                            "performance_metrics_injection", "context_summary"]
        )
        
        # Template d'analyse focalis√©e
        focused_template = PromptTemplate(
            template_id="focused_analysis",
            template_type="targeted",
            base_template="""
<üú≤luciform id="auto_focused_analysis‚õß" type="‚ú∂targeted_introspection">
  <üúÑfocused_context>
    ::INJECT_TARGET_DATA::
    {target_data_injection}
    
    ::INJECT_RELATED_CONTEXT::
    {related_context_injection}
    
    ::INJECT_HISTORICAL_DATA::
    {historical_data_injection}
  </üúÑfocused_context>

  <üúÇfocused_directive>
    Tu es le IntrospectionDaemon en mode d'analyse focalis√©e sur : {analysis_target}
    
    CONTEXTE SP√âCIALIS√â :
    {specialized_context}
    
    MISSION D'ANALYSE CIBL√âE :
    
    1. üéØ ANALYSE SP√âCIALIS√âE :
       - Focus exclusif sur {analysis_target}
       - Analyse approfondie des aspects sp√©cifiques
       - √âvaluation de l'√©tat et des performances
    
    2. üîó ANALYSE RELATIONNELLE :
       - Impact sur les composants connexes
       - D√©pendances et interd√©pendances
       - Effets de r√©seau et propagation
    
    3. üìä ANALYSE HISTORIQUE :
       - √âvolution et tendances observ√©es
       - Patterns de succ√®s et d'√©chec
       - Apprentissages des exp√©riences pass√©es
    
    4. üöÄ RECOMMANDATIONS SP√âCIALIS√âES :
       - Am√©liorations sp√©cifiques au domaine
       - Optimisations techniques pr√©cises
       - Plan d'action d√©taill√© et r√©alisable
    
    R√âSULTAT CIBL√â :
    G√©n√®re une analyse sp√©cialis√©e incluant :
    - Diagnostic pr√©cis de {analysis_target}
    - Recommandations d'am√©lioration sp√©cifiques
    - Plan d'action d√©taill√© avec √©tapes concr√®tes
    - M√©triques de suivi adapt√©es au domaine
  </üúÇfocused_directive>
</üú≤luciform>
            """,
            injection_points=["target_data_injection", "related_context_injection", 
                            "historical_data_injection", "analysis_target", "specialized_context"]
        )
        
        # Template d'optimisation de prompts
        optimization_template = PromptTemplate(
            template_id="prompt_optimization",
            template_type="meta",
            base_template="""
<üú≤luciform id="auto_prompt_optimization‚õß" type="‚ú∂meta_optimization">
  <üúÑoptimization_context>
    ::INJECT_PROMPT_HISTORY::
    {prompt_history_injection}
    
    ::INJECT_EFFECTIVENESS_DATA::
    {effectiveness_data_injection}
    
    ::INJECT_LEARNING_PATTERNS::
    {learning_patterns_injection}
  </üúÑoptimization_context>

  <üúÇoptimization_directive>
    Tu es le IntrospectionDaemon en mode m√©ta-optimisation de prompts.
    
    DONN√âES D'OPTIMISATION :
    {optimization_data_summary}
    
    MISSION DE M√âTA-ANALYSE :
    
    1. üîç ANALYSE DES PATTERNS D'EFFICACIT√â :
       - Identifie les √©l√©ments de prompts les plus efficaces
       - Analyse les corr√©lations succ√®s/structure
       - D√©tecte les patterns d'√©chec r√©currents
    
    2. üß† APPRENTISSAGE ADAPTATIF :
       - Extrait les insights des donn√©es historiques
       - Identifie les am√©liorations possibles
       - Propose des optimisations structurelles
    
    3. üú≤ G√âN√âRATION DE PROMPTS OPTIMIS√âS :
       - Cr√©e des variants am√©lior√©s des templates
       - Int√®gre les apprentissages dans la structure
       - Optimise les points d'injection contextuelle
    
    4. üìä PR√âDICTION D'EFFICACIT√â :
       - Estime l'efficacit√© des nouveaux prompts
       - Identifie les risques potentiels
       - Propose des m√©triques de validation
    
    R√âSULTAT D'OPTIMISATION :
    G√©n√®re des am√©liorations incluant :
    - Templates optimis√©s avec justifications
    - Pr√©dictions d'efficacit√© am√©lior√©e
    - Strat√©gies de test et validation
    - M√©triques de suivi de l'optimisation
  </üúÇoptimization_directive>
</üú≤luciform>
            """,
            injection_points=["prompt_history_injection", "effectiveness_data_injection", 
                            "learning_patterns_injection", "optimization_data_summary"]
        )
        
        # Stockage des templates
        self.prompt_templates = {
            "global_introspection": global_template,
            "focused_analysis": focused_template,
            "prompt_optimization": optimization_template
        }
    
    async def generate_introspection_prompt(self, 
                                          analysis_type: str,
                                          components_data: Dict[str, Any],
                                          capabilities_data: Dict[str, Any]) -> str:
        """
        G√©n√®re un prompt d'introspection optimis√©.
        
        Args:
            analysis_type: Type d'analyse demand√©e
            components_data: Donn√©es des composants
            capabilities_data: Donn√©es des capacit√©s
            
        Returns:
            str: Prompt d'introspection g√©n√©r√©
        """
        print(f"üú≤ G√©n√©ration prompt introspection : {analysis_type}")
        
        # S√©lection du template appropri√©
        template = await self._select_optimal_template(analysis_type, components_data)
        
        # Pr√©paration des donn√©es d'injection
        injection_data = await self._prepare_injection_data(
            template, components_data, capabilities_data
        )
        
        # G√©n√©ration du prompt
        generated_prompt = await self._generate_from_template(template, injection_data)
        
        # Estimation d'efficacit√©
        estimated_effectiveness = await self._estimate_prompt_effectiveness(
            generated_prompt, template, injection_data
        )
        
        # Mise √† jour des statistiques
        await self._update_template_usage(template, estimated_effectiveness)
        
        print(f"‚úÖ Prompt g√©n√©r√© : efficacit√© estim√©e {estimated_effectiveness:.2f}")
        return generated_prompt
    
    async def generate_focused_prompt(self, 
                                    focus: str, 
                                    context_data: Dict[str, Any]) -> str:
        """
        G√©n√®re un prompt focalis√© sur un aspect sp√©cifique.
        
        Args:
            focus: Aspect √† analyser
            context_data: Donn√©es contextuelles
            
        Returns:
            str: Prompt focalis√© g√©n√©r√©
        """
        print(f"üéØ G√©n√©ration prompt focalis√© : {focus}")
        
        # Utilisation du template focalis√©
        template = self.prompt_templates["focused_analysis"]
        
        # Pr√©paration des donn√©es sp√©cialis√©es
        specialized_data = await self._prepare_focused_injection_data(focus, context_data)
        
        # G√©n√©ration
        generated_prompt = await self._generate_from_template(template, specialized_data)
        
        # Mise √† jour
        estimated_effectiveness = await self._estimate_prompt_effectiveness(
            generated_prompt, template, specialized_data
        )
        await self._update_template_usage(template, estimated_effectiveness)
        
        return generated_prompt
    
    async def optimize_prompt_effectiveness(self, 
                                          prompt: str, 
                                          history: List[Dict]) -> str:
        """
        Optimise un prompt bas√© sur l'historique d'efficacit√©.
        
        Args:
            prompt: Prompt √† optimiser
            history: Historique d'efficacit√©
            
        Returns:
            str: Prompt optimis√©
        """
        print("üîß Optimisation d'efficacit√© du prompt...")
        
        # Analyse de l'historique
        optimization_insights = await self._analyze_effectiveness_history(history)
        
        # Identification des am√©liorations
        improvements = await self._identify_prompt_improvements(prompt, optimization_insights)
        
        # Application des optimisations
        optimized_prompt = await self._apply_optimizations(prompt, improvements)
        
        # Apprentissage des patterns
        await self._learn_from_optimization(prompt, optimized_prompt, improvements)
        
        return optimized_prompt
    
    async def _select_optimal_template(self, 
                                     analysis_type: str, 
                                     context: Dict) -> PromptTemplate:
        """S√©lectionne le template optimal pour l'analyse."""
        
        # Logique de s√©lection bas√©e sur le type et l'efficacit√©
        if analysis_type in ["comprehensive", "global", "full"]:
            return self.prompt_templates["global_introspection"]
        elif analysis_type in ["focused", "targeted", "specific"]:
            return self.prompt_templates["focused_analysis"]
        else:
            # S√©lection bas√©e sur l'efficacit√© historique
            best_template = max(
                self.prompt_templates.values(),
                key=lambda t: sum(t.effectiveness_history) / max(len(t.effectiveness_history), 1)
            )
            return best_template
    
    async def _prepare_injection_data(self, 
                                    template: PromptTemplate,
                                    components_data: Dict,
                                    capabilities_data: Dict) -> Dict[str, str]:
        """Pr√©pare les donn√©es d'injection pour le template."""
        
        injection_data = {}
        
        # Injection des donn√©es de composants
        if "component_data_injection" in template.injection_points:
            injection_data["component_data_injection"] = self._format_component_data(components_data)
        
        # Injection de la carte des capacit√©s
        if "capability_map_injection" in template.injection_points:
            injection_data["capability_map_injection"] = self._format_capability_data(capabilities_data)
        
        # Injection des m√©triques de performance
        if "performance_metrics_injection" in template.injection_points:
            injection_data["performance_metrics_injection"] = self._format_performance_metrics()
        
        # R√©sum√© contextuel
        if "context_summary" in template.injection_points:
            injection_data["context_summary"] = self._generate_context_summary(
                components_data, capabilities_data
            )
        
        return injection_data
    
    async def _prepare_focused_injection_data(self, 
                                            focus: str, 
                                            context_data: Dict) -> Dict[str, str]:
        """Pr√©pare les donn√©es d'injection pour l'analyse focalis√©e."""
        
        injection_data = {
            "analysis_target": focus,
            "specialized_context": self._generate_specialized_context(focus, context_data)
        }
        
        # Donn√©es cibl√©es
        if "target_data_injection" in context_data:
            injection_data["target_data_injection"] = str(context_data["target_data_injection"])
        else:
            injection_data["target_data_injection"] = f"Donn√©es sp√©cialis√©es pour {focus}"
        
        # Contexte relationnel
        injection_data["related_context_injection"] = self._extract_related_context(focus, context_data)
        
        # Donn√©es historiques
        injection_data["historical_data_injection"] = self._extract_historical_data(focus)
        
        return injection_data
    
    async def _generate_from_template(self, 
                                    template: PromptTemplate, 
                                    injection_data: Dict[str, str]) -> str:
        """G√©n√®re un prompt √† partir d'un template et de donn√©es d'injection."""
        
        prompt = template.base_template
        
        # Remplacement des points d'injection
        for injection_point, data in injection_data.items():
            placeholder = "{" + injection_point + "}"
            prompt = prompt.replace(placeholder, str(data))
        
        # Nettoyage des placeholders non remplac√©s
        prompt = re.sub(r'\{[^}]+\}', '[DATA_NOT_AVAILABLE]', prompt)
        
        return prompt
    
    async def _estimate_prompt_effectiveness(self, 
                                           prompt: str, 
                                           template: PromptTemplate,
                                           injection_data: Dict) -> float:
        """Estime l'efficacit√© d'un prompt g√©n√©r√©."""
        
        effectiveness = 0.5  # Base
        
        # Bonus bas√© sur l'historique du template
        if template.effectiveness_history:
            avg_effectiveness = sum(template.effectiveness_history) / len(template.effectiveness_history)
            effectiveness += (avg_effectiveness - 0.5) * 0.3
        
        # Bonus bas√© sur la compl√©tude des injections
        injection_completeness = len(injection_data) / max(len(template.injection_points), 1)
        effectiveness += injection_completeness * 0.2
        
        # Bonus bas√© sur la longueur et structure
        if len(prompt) > 1000:  # Prompts d√©taill√©s
            effectiveness += 0.1
        
        if "üú≤luciform" in prompt:  # Format luciforme
            effectiveness += 0.1
        
        return min(effectiveness, 1.0)
    
    async def _update_template_usage(self, 
                                   template: PromptTemplate, 
                                   effectiveness: float):
        """Met √† jour les statistiques d'usage d'un template."""
        
        template.usage_count += 1
        template.effectiveness_history.append(effectiveness)
        template.last_used = datetime.now()
        
        # Limitation de l'historique
        if len(template.effectiveness_history) > 20:
            template.effectiveness_history = template.effectiveness_history[-20:]
        
        # D√©clenchement d'optimisation si n√©cessaire
        if (template.usage_count % self.config["optimization_frequency"] == 0 and
            template.usage_count > 0):
            await self._optimize_template(template)
    
    async def _optimize_template(self, template: PromptTemplate):
        """Optimise un template bas√© sur son historique d'efficacit√©."""
        
        print(f"üîß Optimisation du template {template.template_id}...")
        
        avg_effectiveness = sum(template.effectiveness_history) / len(template.effectiveness_history)
        
        if avg_effectiveness < self.config["min_effectiveness_threshold"]:
            # Template sous-performant, optimisation n√©cessaire
            optimizations = await self._generate_template_optimizations(template)
            await self._apply_template_optimizations(template, optimizations)
            template.optimization_level += 1
            
            print(f"‚úÖ Template optimis√© : niveau {template.optimization_level}")
    
    async def _analyze_effectiveness_history(self, history: List[Dict]) -> Dict[str, Any]:
        """Analyse l'historique d'efficacit√© pour identifier les patterns."""
        
        insights = {
            "average_effectiveness": 0.0,
            "trend": "stable",
            "success_patterns": [],
            "failure_patterns": []
        }
        
        if not history:
            return insights
        
        # Calcul de la moyenne
        effectiveness_scores = [h.get("effectiveness_score", 0.0) for h in history]
        insights["average_effectiveness"] = sum(effectiveness_scores) / len(effectiveness_scores)
        
        # Analyse de tendance
        if len(effectiveness_scores) >= 3:
            recent_avg = sum(effectiveness_scores[-3:]) / 3
            older_avg = sum(effectiveness_scores[:-3]) / max(len(effectiveness_scores) - 3, 1)
            
            if recent_avg > older_avg + 0.1:
                insights["trend"] = "improving"
            elif recent_avg < older_avg - 0.1:
                insights["trend"] = "declining"
        
        return insights
    
    async def _identify_prompt_improvements(self, 
                                          prompt: str, 
                                          insights: Dict) -> List[str]:
        """Identifie les am√©liorations possibles pour un prompt."""
        
        improvements = []
        
        # Am√©liorations bas√©es sur les insights
        if insights["average_effectiveness"] < 0.7:
            improvements.append("enhance_context_injection")
        
        if insights["trend"] == "declining":
            improvements.append("restructure_directive")
        
        # Am√©liorations bas√©es sur la structure
        if len(prompt) < 800:
            improvements.append("add_detailed_instructions")
        
        if "üú≤luciform" not in prompt:
            improvements.append("convert_to_luciform_format")
        
        return improvements
    
    async def _apply_optimizations(self, 
                                 prompt: str, 
                                 improvements: List[str]) -> str:
        """Applique les optimisations identifi√©es √† un prompt."""
        
        optimized_prompt = prompt
        
        for improvement in improvements:
            if improvement == "enhance_context_injection":
                optimized_prompt = self._enhance_context_injection(optimized_prompt)
            elif improvement == "restructure_directive":
                optimized_prompt = self._restructure_directive(optimized_prompt)
            elif improvement == "add_detailed_instructions":
                optimized_prompt = self._add_detailed_instructions(optimized_prompt)
            elif improvement == "convert_to_luciform_format":
                optimized_prompt = self._convert_to_luciform(optimized_prompt)
        
        return optimized_prompt
    
    def _format_component_data(self, components_data: Dict) -> str:
        """Formate les donn√©es de composants pour injection."""
        
        formatted = "Composants analys√©s :\n"
        for comp_name, comp_data in components_data.items():
            status = comp_data.get("status", "unknown")
            health = comp_data.get("health", 0.0)
            formatted += f"- {comp_name}: {status} (sant√©: {health:.2f})\n"
        
        return formatted
    
    def _format_capability_data(self, capabilities_data: Dict) -> str:
        """Formate les donn√©es de capacit√©s pour injection."""
        
        formatted = "Capacit√©s identifi√©es :\n"
        for cap_name, cap_score in capabilities_data.items():
            formatted += f"- {cap_name}: {cap_score:.2f}\n"
        
        return formatted
    
    def _format_performance_metrics(self) -> str:
        """Formate les m√©triques de performance pour injection."""
        
        return "M√©triques de performance : [√Ä impl√©menter avec donn√©es r√©elles]"
    
    def _generate_context_summary(self, components_data: Dict, capabilities_data: Dict) -> str:
        """G√©n√®re un r√©sum√© contextuel."""
        
        comp_count = len(components_data)
        cap_count = len(capabilities_data)
        avg_health = sum(c.get("health", 0.0) for c in components_data.values()) / max(comp_count, 1)
        
        return f"Contexte : {comp_count} composants, {cap_count} capacit√©s, sant√© moyenne {avg_health:.2f}"
    
    def _generate_specialized_context(self, focus: str, context_data: Dict) -> str:
        """G√©n√®re un contexte sp√©cialis√© pour l'analyse focalis√©e."""
        
        return f"Contexte sp√©cialis√© pour {focus} : {len(context_data)} √©l√©ments de donn√©es"
    
    def _extract_related_context(self, focus: str, context_data: Dict) -> str:
        """Extrait le contexte relationnel."""
        
        return f"Contexte relationnel pour {focus} : [√Ä impl√©menter]"
    
    def _extract_historical_data(self, focus: str) -> str:
        """Extrait les donn√©es historiques."""
        
        return f"Donn√©es historiques pour {focus} : [√Ä impl√©menter]"
    
    # M√©thodes d'optimisation (simplifi√©es pour l'instant)
    def _enhance_context_injection(self, prompt: str) -> str:
        return prompt + "\n[ENHANCED_CONTEXT_INJECTION]"
    
    def _restructure_directive(self, prompt: str) -> str:
        return prompt.replace("MISSION", "MISSION RESTRUCTUR√âE")
    
    def _add_detailed_instructions(self, prompt: str) -> str:
        return prompt + "\n[DETAILED_INSTRUCTIONS_ADDED]"
    
    def _convert_to_luciform(self, prompt: str) -> str:
        if "üú≤luciform" not in prompt:
            return f"<üú≤luciform id=\"optimized‚õß\" type=\"‚ú∂enhanced\">\n{prompt}\n</üú≤luciform>"
        return prompt
    
    async def _generate_template_optimizations(self, template: PromptTemplate) -> List[str]:
        """G√©n√®re des optimisations pour un template."""
        return ["improve_structure", "enhance_injections"]
    
    async def _apply_template_optimizations(self, template: PromptTemplate, optimizations: List[str]):
        """Applique les optimisations √† un template."""
        # Impl√©mentation simplifi√©e
        template.base_template += "\n[OPTIMIZED]"
    
    async def _learn_from_optimization(self, original: str, optimized: str, improvements: List[str]):
        """Apprend des optimisations appliqu√©es."""
        
        self.learning_data["optimization_insights"].append({
            "timestamp": datetime.now(),
            "improvements_applied": improvements,
            "original_length": len(original),
            "optimized_length": len(optimized)
        })

if __name__ == "__main__":
    # Test du g√©n√©rateur de prompts
    async def test_prompt_generator():
        print("üú≤ Test du g√©n√©rateur de prompts...")
        
        generator = AutoPromptGenerator()
        
        # Test de g√©n√©ration d'introspection
        components = {"memory": {"status": "active", "health": 0.9}}
        capabilities = {"introspection": 0.8}
        
        prompt = await generator.generate_introspection_prompt(
            "comprehensive", components, capabilities
        )
        
        print(f"‚úÖ Prompt g√©n√©r√© : {len(prompt)} caract√®res")
        print(f"üìä Templates disponibles : {len(generator.prompt_templates)}")
    
    asyncio.run(test_prompt_generator())
