#!/usr/bin/env python3
"""
ðŸ§  IAIntrospectionDaemon - Script Principal â›§

Script principal pour tester et utiliser le Daemon Introspectif IA.
Utilise de vrais moteurs IA (Ollama/OpenAI) pour l'introspection.

CrÃ©Ã© par Alma, Architecte DÃ©moniaque du Nexus Luciforme.
"""

import asyncio
import argparse
import sys
import os
from pathlib import Path

# Ajout du rÃ©pertoire racine au PYTHONPATH
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../../../../')))

from core.ia_introspection_conductor import IAIntrospectionConductor


async def main():
    """Fonction principale du daemon."""
    
    parser = argparse.ArgumentParser(
        description="ðŸ§  IAIntrospectionDaemon - Daemon d'introspection IA-powered",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Exemples d'utilisation:
  python main.py --focus comprehensive
  python main.py --engine ollama --model qwen2.5:7b-instruct
  python main.py --focus memory --save-results
  python main.py --test-engines
        """
    )
    
    parser.add_argument(
        "--focus", 
        choices=["comprehensive", "memory", "tools", "editing"],
        default="comprehensive",
        help="Focus de l'introspection (dÃ©faut: comprehensive)"
    )
    
    parser.add_argument(
        "--engine",
        choices=["ollama", "openai"],
        default="ollama",
        help="Moteur IA principal (dÃ©faut: ollama)"
    )
    
    parser.add_argument(
        "--fallback-engine",
        choices=["ollama", "openai"],
        default="openai",
        help="Moteur IA de secours (dÃ©faut: openai)"
    )
    
    parser.add_argument(
        "--model",
        default=None,
        help="ModÃ¨le spÃ©cifique Ã  utiliser (ex: qwen2.5:7b-instruct)"
    )
    
    parser.add_argument(
        "--test-engines",
        action="store_true",
        help="Teste tous les moteurs IA disponibles"
    )
    
    parser.add_argument(
        "--save-results",
        action="store_true",
        help="Sauvegarde les rÃ©sultats dans les logs"
    )
    
    parser.add_argument(
        "--verbose", "-v",
        action="store_true",
        help="Mode verbeux"
    )
    
    args = parser.parse_args()
    
    print("ðŸ§  IAIntrospectionDaemon - DÃ©marrage")
    print("=" * 50)
    
    try:
        # CrÃ©ation du chef d'orchestre
        conductor = IAIntrospectionConductor(
            primary_engine=args.engine,
            fallback_engine=args.fallback_engine
        )
        
        # Configuration du modÃ¨le si spÃ©cifiÃ©
        if args.model:
            conductor.ai_factory.configure_engine(args.engine, model=args.model)
        
        # Configuration de la sauvegarde
        conductor.config["save_results"] = args.save_results
        
        # Test des moteurs IA si demandÃ©
        if args.test_engines:
            print("ðŸ¤– Test des moteurs IA...")
            engine_status = await conductor.test_ai_engines()
            
            print("\nðŸ“Š Statut des moteurs IA:")
            for engine, status in engine_status.items():
                status_icon = "âœ…" if status else "âŒ"
                print(f"  {status_icon} {engine}: {'Disponible' if status else 'Non disponible'}")
            
            if not any(engine_status.values()):
                print("\nâŒ Aucun moteur IA disponible. VÃ©rifiez:")
                print("  - Ollama: ollama serve")
                print("  - OpenAI: OPENAI_API_KEY")
                return 1
            
            print()
        
        # Initialisation du daemon
        print("ðŸ”§ Initialisation du daemon...")
        success = await conductor.initialize()
        
        if not success:
            print("âŒ Ã‰chec d'initialisation du daemon")
            return 1
        
        print("âœ… Daemon initialisÃ© avec succÃ¨s")
        
        # ExÃ©cution de l'introspection
        print(f"\nðŸ§  DÃ©marrage introspection: {args.focus}")
        print("-" * 30)
        
        result = await conductor.conduct_ai_introspection(args.focus)
        
        # Affichage des rÃ©sultats
        print(f"\nðŸ“Š RÃ©sultats de l'introspection:")
        print(f"  âœ… SuccÃ¨s: {result.success}")
        print(f"  â±ï¸ Temps d'exÃ©cution: {result.execution_time:.2f}s")
        print(f"  ðŸ¤– Moteur utilisÃ©: {result.ai_engine_used}")
        
        if result.errors:
            print(f"  âŒ Erreurs: {len(result.errors)}")
            for error in result.errors:
                print(f"    - {error}")
        
        # Affichage dÃ©taillÃ© si mode verbeux
        if args.verbose:
            print(f"\nðŸ” DÃ©tails des analyses:")
            
            if result.memory_analysis:
                print(f"  ðŸ§  MemoryEngine: {'âœ…' if result.memory_analysis.get('success') else 'âŒ'}")
            
            if result.tool_analysis:
                print(f"  ðŸ› ï¸ ToolRegistry: {'âœ…' if result.tool_analysis.get('success') else 'âŒ'}")
            
            if result.editing_analysis:
                print(f"  ðŸ“ EditingSession: {'âœ…' if result.editing_analysis.get('success') else 'âŒ'}")
            
            if result.synthesis_insights:
                print(f"  ðŸ§  SynthÃ¨se: {'âœ…' if result.synthesis_insights.get('success') else 'âŒ'}")
        
        # Sauvegarde des rÃ©sultats
        if args.save_results:
            print(f"\nðŸ’¾ RÃ©sultats sauvegardÃ©s dans les logs")
        
        print(f"\nðŸŽ‰ Introspection terminÃ©e avec succÃ¨s!")
        return 0
        
    except KeyboardInterrupt:
        print("\nâ¹ï¸ Interruption utilisateur")
        return 1
    except Exception as e:
        print(f"\nâŒ Erreur fatale: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        return 1


async def test_individual_components():
    """Test des composants individuels."""
    print("ðŸ§ª Test des composants individuels...")
    
    try:
        # Test des moteurs IA
        from ai_engines.ai_engine_factory import AIEngineFactory
        factory = AIEngineFactory()
        
        print("ðŸ¤– Test des moteurs IA...")
        engine_status = await factory.test_all_engines()
        print(f"Statut: {engine_status}")
        
        # Test du navigateur MemoryEngine
        if engine_status.get("ollama", False):
            print("ðŸ§  Test du navigateur MemoryEngine...")
            from ai_engines.ollama_engine import OllamaEngine
            from core.memory_engine_navigator import MemoryEngineNavigator
            
            ai_engine = OllamaEngine()
            
            # Test avec MemoryEngine simulÃ©
            class MockMemoryEngine:
                def get_memory_statistics(self):
                    return {"total": 0, "strata": {}}
                def find_by_strata(self, strata):
                    return []
                backend_type = "filesystem"
            
            navigator = MemoryEngineNavigator(MockMemoryEngine(), ai_engine)
            result = await navigator.explore_memory_strata()
            print(f"RÃ©sultat navigation: {result.get('success', False)}")
        
        print("âœ… Tests terminÃ©s")
        
    except Exception as e:
        print(f"âŒ Erreur tests: {e}")


if __name__ == "__main__":
    # VÃ©rification des arguments pour les tests
    if len(sys.argv) > 1 and sys.argv[1] == "--test-components":
        asyncio.run(test_individual_components())
    else:
        exit_code = asyncio.run(main())
        sys.exit(exit_code) 