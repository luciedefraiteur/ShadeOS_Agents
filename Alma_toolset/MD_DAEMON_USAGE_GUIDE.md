# ğŸ¤– Guide d'Utilisation - MD Daemon avec OpenAI/Ollama

**Date :** 2025-08-02 11:50  
**CrÃ©Ã© par :** Alma, Architecte DÃ©moniaque du Nexus Luciforme  
**Version :** 1.0 avec Force Ollama Debug  

---

## ğŸ¯ **Modes d'Utilisation**

### **ğŸ¤– Mode Production (OpenAI) :**
```bash
# Daemon complet avec OpenAI et budget contrÃ´lÃ©
python Alma_toolset/md_daemon_core.py --root . --budget-hour 2.0 --budget-day 20.0

# Analyse avec exclusions
python Alma_toolset/md_daemon_core.py --root . --exclude ShadeOS .git __pycache__

# Budget limitÃ© pour tests
python Alma_toolset/md_daemon_core.py --root . --budget-hour 0.50
```

### **ğŸ¦™ Mode Debug (Ollama - Gratuit) :**
```bash
# Force Ollama pour debug sans coÃ»t
python Alma_toolset/md_daemon_core.py --root . --force-ollama

# Debug avec exclusions spÃ©cifiques
python Alma_toolset/md_daemon_core.py --root . --force-ollama --exclude ShadeOS private_docs

# Test rapide sur rÃ©pertoire spÃ©cifique
python Alma_toolset/md_daemon_core.py --root ./docs --force-ollama
```

### **ğŸ§ª Tests Individuels :**
```bash
# Test analyseur OpenAI seul
python Alma_toolset/openai_analyzer.py

# Test analyseur avec force Ollama
python Alma_toolset/openai_analyzer.py --force-ollama

# Test analyseur contextuel
python Alma_toolset/contextual_md_analyzer.py
```

---

## ğŸ”§ **Options de Configuration**

### **ğŸ“‹ Arguments Principaux :**

#### **--root, -r** (dÃ©faut: ".")
RÃ©pertoire racine Ã  analyser
```bash
python Alma_toolset/md_daemon_core.py --root /path/to/docs
```

#### **--budget-hour** (dÃ©faut: 2.0)
Budget OpenAI par heure en dollars
```bash
python Alma_toolset/md_daemon_core.py --budget-hour 1.0
```

#### **--exclude, -e** (dÃ©faut: ShadeOS .git __pycache__ node_modules)
RÃ©pertoires Ã  exclure
```bash
python Alma_toolset/md_daemon_core.py --exclude ShadeOS private_docs temp
```

#### **--force-ollama** (nouveau !)
Force l'utilisation d'Ollama (bypass OpenAI)
```bash
python Alma_toolset/md_daemon_core.py --force-ollama
```

---

## ğŸ¦™ **Configuration Ollama**

### **ğŸ“‹ PrÃ©requis :**
1. **Installation Ollama :**
   ```bash
   # Installation (voir https://ollama.ai)
   curl -fsSL https://ollama.ai/install.sh | sh
   ```

2. **Installation du modÃ¨le Mistral :**
   ```bash
   ollama pull mistral
   ```

3. **VÃ©rification :**
   ```bash
   ollama list
   # Doit afficher: mistral
   ```

### **ğŸ¯ Avantages Ollama :**
- **Gratuit** : Aucun coÃ»t d'API
- **Local** : Pas de dÃ©pendance rÃ©seau
- **PrivÃ©** : DonnÃ©es restent locales
- **Debug** : Parfait pour dÃ©veloppement

### **âš ï¸ Limitations Ollama :**
- **Plus lent** : ~10-15s par analyse vs 1-2s OpenAI
- **QualitÃ©** : LÃ©gÃ¨rement infÃ©rieure Ã  GPT-4
- **Ressources** : Utilise CPU/RAM local

---

## ğŸ“Š **Comparaison des Modes**

| Aspect | OpenAI | Ollama | Simulation |
|--------|--------|--------|------------|
| **CoÃ»t** | $0.001-0.01/doc | Gratuit | Gratuit |
| **Vitesse** | 1-2s | 10-15s | 0.1s |
| **QualitÃ©** | Excellente | Bonne | Basique |
| **RÃ©seau** | Requis | Non | Non |
| **PrivacitÃ©** | Cloud | Local | Local |
| **Debug** | CoÃ»teux | Parfait | LimitÃ© |

---

## ğŸ¯ **Cas d'Usage RecommandÃ©s**

### **ğŸ¤– Production (OpenAI) :**
- **Documentation finale** : Analyse de qualitÃ© maximale
- **Rapports importants** : Classification prÃ©cise
- **IntÃ©gration continue** : Avec budget contrÃ´lÃ©

### **ğŸ¦™ DÃ©veloppement (Ollama) :**
- **Tests de fonctionnalitÃ©s** : Sans coÃ»t
- **Debug d'algorithmes** : ItÃ©rations rapides
- **DÃ©veloppement local** : Pas de dÃ©pendance rÃ©seau

### **âš¡ Simulation :**
- **Tests unitaires** : Validation de structure
- **CI/CD** : VÃ©rification sans coÃ»t
- **Fallback** : Quand AI indisponible

---

## ğŸ” **Exemples Pratiques**

### **ğŸ§ª Session de Debug :**
```bash
# 1. Test rapide avec Ollama
python Alma_toolset/openai_analyzer.py --force-ollama

# 2. Daemon debug sur sous-rÃ©pertoire
python Alma_toolset/md_daemon_core.py --root ./test_docs --force-ollama

# 3. Analyse contextuelle debug
python Alma_toolset/contextual_md_analyzer.py
```

### **ğŸš€ DÃ©ploiement Production :**
```bash
# 1. VÃ©rification environnement
python Alma_toolset/openai_analyzer.py

# 2. Daemon avec budget contrÃ´lÃ©
python Alma_toolset/md_daemon_core.py --root . --budget-hour 1.0 --exclude ShadeOS

# 3. Monitoring des coÃ»ts
# (voir rapport gÃ©nÃ©rÃ©: MD_DAEMON_STATUS.md)
```

### **ğŸ“Š Analyse Comparative :**
```bash
# 1. Analyse OpenAI
python Alma_toolset/openai_analyzer.py > results_openai.txt

# 2. Analyse Ollama
python Alma_toolset/openai_analyzer.py --force-ollama > results_ollama.txt

# 3. Comparaison des rÃ©sultats
diff results_openai.txt results_ollama.txt
```

---

## ğŸ› ï¸ **Troubleshooting**

### **âŒ ProblÃ¨mes Courants :**

#### **OpenAI API Key manquante :**
```
âš ï¸ OPENAI_API_KEY not found in environment
ğŸ’¡ Make sure your ~/.env file contains: OPENAI_API_KEY=your_key_here
```
**Solution :** Ajouter la clÃ© dans `~/.env`

#### **Ollama non disponible :**
```
ğŸ¦™ Ollama not installed
ğŸ’¡ Install from: https://ollama.ai
```
**Solution :** Installer Ollama et le modÃ¨le Mistral

#### **Budget dÃ©passÃ© :**
```
ğŸ’° Hourly budget exceeded: 0.0050 + 0.0010 > 0.0050
```
**Solution :** Augmenter `--budget-hour` ou utiliser `--force-ollama`

#### **ModÃ¨le Mistral manquant :**
```
ğŸ¦™ Ollama available but model mistral not found
ğŸ’¡ Run: ollama pull mistral
```
**Solution :** `ollama pull mistral`

---

## ğŸ“ˆ **Monitoring et MÃ©triques**

### **ğŸ“Š Rapport de Statut :**
Le daemon gÃ©nÃ¨re automatiquement `MD_DAEMON_STATUS.md` avec :
- **Statistiques de traitement** : Fichiers, analyses, partitions
- **CoÃ»ts OpenAI** : Usage quotidien/horaire, budget restant
- **Performance** : Temps de traitement, erreurs
- **Configuration** : ParamÃ¨tres actifs

### **ğŸ’° Gestion des CoÃ»ts :**
```bash
# Budget trÃ¨s limitÃ© pour tests
python Alma_toolset/md_daemon_core.py --budget-hour 0.10

# Mode gratuit pour dÃ©veloppement
python Alma_toolset/md_daemon_core.py --force-ollama

# Monitoring en temps rÃ©el
tail -f MD_DAEMON_STATUS.md
```

---

## ğŸ‰ **Bonnes Pratiques**

### **âœ… DÃ©veloppement :**
1. **Commencer par Ollama** : `--force-ollama` pour tests
2. **Tester sur petit dataset** : `--root ./test_docs`
3. **Exclure les gros rÃ©pertoires** : `--exclude ShadeOS`
4. **Monitorer les performances** : VÃ©rifier les temps de traitement

### **âœ… Production :**
1. **Budget appropriÃ©** : `--budget-hour` selon usage
2. **Exclusions optimisÃ©es** : Ã‰viter les fichiers inutiles
3. **Monitoring actif** : Surveiller `MD_DAEMON_STATUS.md`
4. **Fallback Ollama** : En cas de problÃ¨me OpenAI

### **âœ… Debug :**
1. **Force Ollama** : `--force-ollama` pour debug gratuit
2. **Logs dÃ©taillÃ©s** : Observer les messages de traitement
3. **Tests isolÃ©s** : Analyseurs individuels d'abord
4. **Comparaison** : OpenAI vs Ollama vs Simulation

---

**ğŸ–¤â›§âœ¨ Guide complet pour maÃ®triser le MD Daemon avec toutes ses options mystiques ! âœ¨â›§ğŸ–¤**

*"L'intelligence artificielle locale et cloud s'unissent pour rÃ©vÃ©ler les secrets documentaires."*
